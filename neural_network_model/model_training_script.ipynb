{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023b12dd-208c-4509-a001-b60d1f0529fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 13:54:47.722793: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-25 13:54:47.725783: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-25 13:54:47.761073: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-25 13:54:47.761917: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-25 13:54:57.077232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Running combo 1/5: [238, 238, 238], relu, dropout=0.05, l2=0.0005\n",
      "Epoch 1/200\n",
      "1422/1422 [==============================] - 3s 2ms/step - loss: 135527488.0000 - val_loss: 69474088.0000\n",
      "Epoch 2/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 53997476.0000 - val_loss: 54561696.0000\n",
      "Epoch 3/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 48552812.0000 - val_loss: 51058220.0000\n",
      "Epoch 4/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 45138856.0000 - val_loss: 47822688.0000\n",
      "Epoch 5/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 41968952.0000 - val_loss: 44686408.0000\n",
      "Epoch 6/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 39143776.0000 - val_loss: 42201368.0000\n",
      "Epoch 7/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 36417324.0000 - val_loss: 39590312.0000\n",
      "Epoch 8/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 34178832.0000 - val_loss: 37705188.0000\n",
      "Epoch 9/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 32561944.0000 - val_loss: 35949616.0000\n",
      "Epoch 10/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 30668192.0000 - val_loss: 33432640.0000\n",
      "Epoch 11/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 28407852.0000 - val_loss: 30445978.0000\n",
      "Epoch 12/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 25488962.0000 - val_loss: 27084272.0000\n",
      "Epoch 13/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 22436460.0000 - val_loss: 23116274.0000\n",
      "Epoch 14/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 20125836.0000 - val_loss: 21199736.0000\n",
      "Epoch 15/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18823176.0000 - val_loss: 20057386.0000\n",
      "Epoch 16/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18114658.0000 - val_loss: 19498662.0000\n",
      "Epoch 17/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17664494.0000 - val_loss: 18997128.0000\n",
      "Epoch 18/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17360378.0000 - val_loss: 18600564.0000\n",
      "Epoch 19/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17106236.0000 - val_loss: 18371690.0000\n",
      "Epoch 20/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16973708.0000 - val_loss: 18111660.0000\n",
      "Epoch 21/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16784716.0000 - val_loss: 18020112.0000\n",
      "Epoch 22/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16632708.0000 - val_loss: 17768898.0000\n",
      "Epoch 23/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16493877.0000 - val_loss: 17583466.0000\n",
      "Epoch 24/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16470827.0000 - val_loss: 17426430.0000\n",
      "Epoch 25/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16371126.0000 - val_loss: 17528650.0000\n",
      "Epoch 26/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16291724.0000 - val_loss: 17207794.0000\n",
      "Epoch 27/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16319930.0000 - val_loss: 17115004.0000\n",
      "Epoch 28/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16137446.0000 - val_loss: 17256542.0000\n",
      "Epoch 29/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16100679.0000 - val_loss: 16959884.0000\n",
      "Epoch 30/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16055724.0000 - val_loss: 16917722.0000\n",
      "Epoch 31/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16055499.0000 - val_loss: 16829826.0000\n",
      "Epoch 32/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15942771.0000 - val_loss: 16928648.0000\n",
      "Epoch 33/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15932587.0000 - val_loss: 16758723.0000\n",
      "Epoch 34/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15878755.0000 - val_loss: 16681184.0000\n",
      "Epoch 35/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15898413.0000 - val_loss: 16642968.0000\n",
      "Epoch 36/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15803832.0000 - val_loss: 16546736.0000\n",
      "Epoch 37/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15768860.0000 - val_loss: 16691355.0000\n",
      "Epoch 38/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15818498.0000 - val_loss: 16641478.0000\n",
      "Epoch 39/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15700101.0000 - val_loss: 16342660.0000\n",
      "Epoch 40/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15830255.0000 - val_loss: 16349168.0000\n",
      "Epoch 41/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15742668.0000 - val_loss: 16259463.0000\n",
      "Epoch 42/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15634254.0000 - val_loss: 16692485.0000\n",
      "Epoch 43/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15742552.0000 - val_loss: 16288175.0000\n",
      "Epoch 44/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15703628.0000 - val_loss: 16263251.0000\n",
      "Epoch 45/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15675435.0000 - val_loss: 16226971.0000\n",
      "Epoch 46/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15625724.0000 - val_loss: 16139203.0000\n",
      "Epoch 47/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15635595.0000 - val_loss: 16304871.0000\n",
      "Epoch 48/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15590481.0000 - val_loss: 16269209.0000\n",
      "Epoch 49/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15540386.0000 - val_loss: 16074826.0000\n",
      "Epoch 50/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15589305.0000 - val_loss: 16194749.0000\n",
      "Epoch 51/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15560865.0000 - val_loss: 16185626.0000\n",
      "Epoch 52/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15497603.0000 - val_loss: 16018600.0000\n",
      "Epoch 53/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15518730.0000 - val_loss: 15975017.0000\n",
      "Epoch 54/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15543496.0000 - val_loss: 15952736.0000\n",
      "Epoch 55/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15423921.0000 - val_loss: 15992972.0000\n",
      "Epoch 56/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15457531.0000 - val_loss: 15931055.0000\n",
      "Epoch 57/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15525850.0000 - val_loss: 16131774.0000\n",
      "Epoch 58/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15482663.0000 - val_loss: 15944712.0000\n",
      "Epoch 59/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15448482.0000 - val_loss: 15986148.0000\n",
      "Epoch 60/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15444509.0000 - val_loss: 15928599.0000\n",
      "Epoch 61/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15424556.0000 - val_loss: 16019526.0000\n",
      "Epoch 62/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15405065.0000 - val_loss: 15950792.0000\n",
      "Epoch 63/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15408424.0000 - val_loss: 15798816.0000\n",
      "Epoch 64/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15351105.0000 - val_loss: 15794778.0000\n",
      "Epoch 65/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15360040.0000 - val_loss: 15799777.0000\n",
      "Epoch 66/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15356833.0000 - val_loss: 15773273.0000\n",
      "Epoch 67/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15338950.0000 - val_loss: 15739492.0000\n",
      "Epoch 68/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15317846.0000 - val_loss: 15763525.0000\n",
      "Epoch 69/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15306760.0000 - val_loss: 15680745.0000\n",
      "Epoch 70/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15318750.0000 - val_loss: 15774861.0000\n",
      "Epoch 71/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15249837.0000 - val_loss: 15936603.0000\n",
      "Epoch 72/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15359337.0000 - val_loss: 15958248.0000\n",
      "Epoch 73/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15272793.0000 - val_loss: 15683800.0000\n",
      "Epoch 74/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15244871.0000 - val_loss: 15755024.0000\n",
      "Epoch 75/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15162791.0000 - val_loss: 15813681.0000\n",
      "Epoch 76/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15234573.0000 - val_loss: 15783593.0000\n",
      "Epoch 77/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15224016.0000 - val_loss: 15631178.0000\n",
      "Epoch 78/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15132444.0000 - val_loss: 15609726.0000\n",
      "Epoch 79/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15148155.0000 - val_loss: 15526915.0000\n",
      "Epoch 80/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15191638.0000 - val_loss: 15529686.0000\n",
      "Epoch 81/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15186441.0000 - val_loss: 15490712.0000\n",
      "Epoch 82/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15131081.0000 - val_loss: 15476142.0000\n",
      "Epoch 83/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15160791.0000 - val_loss: 15430656.0000\n",
      "Epoch 84/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15058142.0000 - val_loss: 15523729.0000\n",
      "Epoch 85/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15065244.0000 - val_loss: 15448828.0000\n",
      "Epoch 86/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15096494.0000 - val_loss: 16225040.0000\n",
      "Epoch 87/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15060222.0000 - val_loss: 15821874.0000\n",
      "Epoch 88/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14993019.0000 - val_loss: 15306773.0000\n",
      "Epoch 89/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15034408.0000 - val_loss: 15352615.0000\n",
      "Epoch 90/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14916761.0000 - val_loss: 15344777.0000\n",
      "Epoch 91/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14978656.0000 - val_loss: 15596839.0000\n",
      "Epoch 92/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14904713.0000 - val_loss: 15344349.0000\n",
      "Epoch 93/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14845660.0000 - val_loss: 15538562.0000\n",
      "Epoch 94/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14846930.0000 - val_loss: 15168312.0000\n",
      "Epoch 95/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14801720.0000 - val_loss: 15170346.0000\n",
      "Epoch 96/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14783925.0000 - val_loss: 15732250.0000\n",
      "Epoch 97/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14810322.0000 - val_loss: 15016702.0000\n",
      "Epoch 98/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14806494.0000 - val_loss: 15217347.0000\n",
      "Epoch 99/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14703062.0000 - val_loss: 14978905.0000\n",
      "Epoch 100/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14641487.0000 - val_loss: 14942763.0000\n",
      "Epoch 101/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14618822.0000 - val_loss: 14899164.0000\n",
      "Epoch 102/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14571263.0000 - val_loss: 14996141.0000\n",
      "Epoch 103/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14589330.0000 - val_loss: 14880989.0000\n",
      "Epoch 104/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14480869.0000 - val_loss: 14761428.0000\n",
      "Epoch 105/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14347814.0000 - val_loss: 14584158.0000\n",
      "Epoch 106/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14417036.0000 - val_loss: 14516891.0000\n",
      "Epoch 107/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14263787.0000 - val_loss: 14570856.0000\n",
      "Epoch 108/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14242154.0000 - val_loss: 14371389.0000\n",
      "Epoch 109/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14073749.0000 - val_loss: 14247126.0000\n",
      "Epoch 110/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14026903.0000 - val_loss: 14164570.0000\n",
      "Epoch 111/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13998359.0000 - val_loss: 14083282.0000\n",
      "Epoch 112/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13885873.0000 - val_loss: 14072516.0000\n",
      "Epoch 113/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13757231.0000 - val_loss: 13853941.0000\n",
      "Epoch 114/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13623085.0000 - val_loss: 13700923.0000\n",
      "Epoch 115/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13469701.0000 - val_loss: 13608037.0000\n",
      "Epoch 116/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13373273.0000 - val_loss: 13291985.0000\n",
      "Epoch 117/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13279336.0000 - val_loss: 13298195.0000\n",
      "Epoch 118/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13163725.0000 - val_loss: 13226181.0000\n",
      "Epoch 119/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13004686.0000 - val_loss: 12984286.0000\n",
      "Epoch 120/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12869516.0000 - val_loss: 12765932.0000\n",
      "Epoch 121/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12664759.0000 - val_loss: 12710302.0000\n",
      "Epoch 122/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12528952.0000 - val_loss: 12358171.0000\n",
      "Epoch 123/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12321936.0000 - val_loss: 12060947.0000\n",
      "Epoch 124/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12151610.0000 - val_loss: 12062155.0000\n",
      "Epoch 125/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11956124.0000 - val_loss: 11561733.0000\n",
      "Epoch 126/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11865173.0000 - val_loss: 11512799.0000\n",
      "Epoch 127/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11723946.0000 - val_loss: 11524741.0000\n",
      "Epoch 128/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11580120.0000 - val_loss: 11249162.0000\n",
      "Epoch 129/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11343712.0000 - val_loss: 10839315.0000\n",
      "Epoch 130/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11268178.0000 - val_loss: 10541725.0000\n",
      "Epoch 131/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 11112129.0000 - val_loss: 10763282.0000\n",
      "Epoch 132/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10946036.0000 - val_loss: 10218699.0000\n",
      "Epoch 133/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10822436.0000 - val_loss: 9906176.0000\n",
      "Epoch 134/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10718244.0000 - val_loss: 9709161.0000\n",
      "Epoch 135/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10610888.0000 - val_loss: 9691789.0000\n",
      "Epoch 136/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10536454.0000 - val_loss: 9502864.0000\n",
      "Epoch 137/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10275751.0000 - val_loss: 9651556.0000\n",
      "Epoch 138/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10242664.0000 - val_loss: 9013283.0000\n",
      "Epoch 139/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10079623.0000 - val_loss: 8962340.0000\n",
      "Epoch 140/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 10070343.0000 - val_loss: 8688312.0000\n",
      "Epoch 141/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9911897.0000 - val_loss: 8595606.0000\n",
      "Epoch 142/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9826304.0000 - val_loss: 8484378.0000\n",
      "Epoch 143/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9737739.0000 - val_loss: 8355827.5000\n",
      "Epoch 144/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9667750.0000 - val_loss: 8065199.5000\n",
      "Epoch 145/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9610967.0000 - val_loss: 8225546.0000\n",
      "Epoch 146/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9560972.0000 - val_loss: 7968232.5000\n",
      "Epoch 147/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9412871.0000 - val_loss: 8591654.0000\n",
      "Epoch 148/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9370182.0000 - val_loss: 7799635.0000\n",
      "Epoch 149/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9286322.0000 - val_loss: 7699163.5000\n",
      "Epoch 150/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9282652.0000 - val_loss: 7595708.0000\n",
      "Epoch 151/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9175407.0000 - val_loss: 7782695.0000\n",
      "Epoch 152/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9141774.0000 - val_loss: 7486906.5000\n",
      "Epoch 153/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9171080.0000 - val_loss: 7834589.5000\n",
      "Epoch 154/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9056495.0000 - val_loss: 7410792.5000\n",
      "Epoch 155/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9025341.0000 - val_loss: 7300373.5000\n",
      "Epoch 156/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 9043902.0000 - val_loss: 7520996.0000\n",
      "Epoch 157/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8982931.0000 - val_loss: 7254066.5000\n",
      "Epoch 158/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8943614.0000 - val_loss: 7577728.5000\n",
      "Epoch 159/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8897749.0000 - val_loss: 7192758.5000\n",
      "Epoch 160/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8883799.0000 - val_loss: 7445137.5000\n",
      "Epoch 161/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8880751.0000 - val_loss: 7177477.5000\n",
      "Epoch 162/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8839990.0000 - val_loss: 6996643.0000\n",
      "Epoch 163/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8755991.0000 - val_loss: 6983224.5000\n",
      "Epoch 164/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8683849.0000 - val_loss: 7108612.0000\n",
      "Epoch 165/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8760270.0000 - val_loss: 6995076.0000\n",
      "Epoch 166/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8712022.0000 - val_loss: 6881788.0000\n",
      "Epoch 167/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8686141.0000 - val_loss: 6928561.5000\n",
      "Epoch 168/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8615537.0000 - val_loss: 6899722.5000\n",
      "Epoch 169/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8585979.0000 - val_loss: 6730949.5000\n",
      "Epoch 170/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8547662.0000 - val_loss: 6780969.5000\n",
      "Epoch 171/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8621999.0000 - val_loss: 6978278.5000\n",
      "Epoch 172/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8602161.0000 - val_loss: 6776461.0000\n",
      "Epoch 173/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8451857.0000 - val_loss: 6750197.5000\n",
      "Epoch 174/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8468075.0000 - val_loss: 6629752.0000\n",
      "Epoch 175/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8524177.0000 - val_loss: 6606608.0000\n",
      "Epoch 176/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8430086.0000 - val_loss: 6645493.0000\n",
      "Epoch 177/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8383592.0000 - val_loss: 6624351.5000\n",
      "Epoch 178/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8411920.0000 - val_loss: 6569153.0000\n",
      "Epoch 179/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8350850.5000 - val_loss: 6958443.0000\n",
      "Epoch 180/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8285471.0000 - val_loss: 6606194.5000\n",
      "Epoch 181/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8379992.5000 - val_loss: 6769912.0000\n",
      "Epoch 182/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8327747.5000 - val_loss: 6794612.5000\n",
      "Epoch 183/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8287010.0000 - val_loss: 6550041.5000\n",
      "Epoch 184/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8260905.5000 - val_loss: 6722419.0000\n",
      "Epoch 185/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8237922.5000 - val_loss: 6452931.0000\n",
      "Epoch 186/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8322434.0000 - val_loss: 6328687.5000\n",
      "Epoch 187/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8211640.5000 - val_loss: 6438972.0000\n",
      "Epoch 188/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8227041.0000 - val_loss: 6479574.0000\n",
      "Epoch 189/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8273549.0000 - val_loss: 6447657.0000\n",
      "Epoch 190/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8238296.5000 - val_loss: 6232195.5000\n",
      "Epoch 191/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8117825.0000 - val_loss: 6353470.5000\n",
      "Epoch 192/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8126440.0000 - val_loss: 6362200.5000\n",
      "Epoch 193/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8192913.0000 - val_loss: 6355325.5000\n",
      "Epoch 194/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8068835.0000 - val_loss: 6207090.5000\n",
      "Epoch 195/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8104502.0000 - val_loss: 6684819.5000\n",
      "Epoch 196/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8099120.5000 - val_loss: 6359789.0000\n",
      "Epoch 197/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8061695.5000 - val_loss: 6212957.5000\n",
      "Epoch 198/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8064226.5000 - val_loss: 6359135.5000\n",
      "Epoch 199/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 8081062.5000 - val_loss: 6235256.5000\n",
      "Epoch 200/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 7991568.5000 - val_loss: 6039750.0000\n",
      "1219/1219 [==============================] - 1s 388us/step\n",
      "\n",
      "üîÅ Running combo 2/5: [256, 128, 64], relu, dropout=0.05, l2=0.0005\n",
      "Epoch 1/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 166034624.0000 - val_loss: 128426240.0000\n",
      "Epoch 2/200\n",
      "1422/1422 [==============================] - 1s 960us/step - loss: 77405352.0000 - val_loss: 59857368.0000\n",
      "Epoch 3/200\n",
      "1422/1422 [==============================] - 1s 934us/step - loss: 52390140.0000 - val_loss: 54389444.0000\n",
      "Epoch 4/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 49167540.0000 - val_loss: 51827756.0000\n",
      "Epoch 5/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 46853848.0000 - val_loss: 49629044.0000\n",
      "Epoch 6/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 44821820.0000 - val_loss: 47551048.0000\n",
      "Epoch 7/200\n",
      "1422/1422 [==============================] - 1s 925us/step - loss: 42940072.0000 - val_loss: 45767148.0000\n",
      "Epoch 8/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 41425092.0000 - val_loss: 44251056.0000\n",
      "Epoch 9/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 39799620.0000 - val_loss: 42818816.0000\n",
      "Epoch 10/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 38290296.0000 - val_loss: 41300668.0000\n",
      "Epoch 11/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 36776984.0000 - val_loss: 39681952.0000\n",
      "Epoch 12/200\n",
      "1422/1422 [==============================] - 1s 915us/step - loss: 35164992.0000 - val_loss: 38474260.0000\n",
      "Epoch 13/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 34065992.0000 - val_loss: 37216924.0000\n",
      "Epoch 14/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 33077122.0000 - val_loss: 36078844.0000\n",
      "Epoch 15/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 31832976.0000 - val_loss: 34705508.0000\n",
      "Epoch 16/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 30623736.0000 - val_loss: 33092726.0000\n",
      "Epoch 17/200\n",
      "1422/1422 [==============================] - 1s 909us/step - loss: 29015398.0000 - val_loss: 31061934.0000\n",
      "Epoch 18/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 27180064.0000 - val_loss: 28800336.0000\n",
      "Epoch 19/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 25169856.0000 - val_loss: 26274448.0000\n",
      "Epoch 20/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 23344778.0000 - val_loss: 24129548.0000\n",
      "Epoch 21/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 21959494.0000 - val_loss: 22621988.0000\n",
      "Epoch 22/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 20844366.0000 - val_loss: 21804940.0000\n",
      "Epoch 23/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 20026094.0000 - val_loss: 20740164.0000\n",
      "Epoch 24/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 19670840.0000 - val_loss: 20232318.0000\n",
      "Epoch 25/200\n",
      "1422/1422 [==============================] - 1s 908us/step - loss: 19059526.0000 - val_loss: 20237324.0000\n",
      "Epoch 26/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 18705074.0000 - val_loss: 19370492.0000\n",
      "Epoch 27/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 18505658.0000 - val_loss: 19099228.0000\n",
      "Epoch 28/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 18441128.0000 - val_loss: 18897942.0000\n",
      "Epoch 29/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 18220070.0000 - val_loss: 18907180.0000\n",
      "Epoch 30/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 17990488.0000 - val_loss: 18490266.0000\n",
      "Epoch 31/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 17894714.0000 - val_loss: 18368762.0000\n",
      "Epoch 32/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 17853128.0000 - val_loss: 18307132.0000\n",
      "Epoch 33/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 17756332.0000 - val_loss: 18018400.0000\n",
      "Epoch 34/200\n",
      "1422/1422 [==============================] - 1s 935us/step - loss: 17630446.0000 - val_loss: 17912802.0000\n",
      "Epoch 35/200\n",
      "1422/1422 [==============================] - 1s 935us/step - loss: 17571878.0000 - val_loss: 17813598.0000\n",
      "Epoch 36/200\n",
      "1422/1422 [==============================] - 1s 932us/step - loss: 17399166.0000 - val_loss: 17693416.0000\n",
      "Epoch 37/200\n",
      "1422/1422 [==============================] - 1s 932us/step - loss: 17539524.0000 - val_loss: 17686206.0000\n",
      "Epoch 38/200\n",
      "1422/1422 [==============================] - 1s 933us/step - loss: 17483380.0000 - val_loss: 17512482.0000\n",
      "Epoch 39/200\n",
      "1422/1422 [==============================] - 1s 931us/step - loss: 17261754.0000 - val_loss: 17383292.0000\n",
      "Epoch 40/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 17157104.0000 - val_loss: 17246588.0000\n",
      "Epoch 41/200\n",
      "1422/1422 [==============================] - 1s 926us/step - loss: 17203460.0000 - val_loss: 17191310.0000\n",
      "Epoch 42/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 17158768.0000 - val_loss: 17514582.0000\n",
      "Epoch 43/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 17058558.0000 - val_loss: 17112798.0000\n",
      "Epoch 44/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 17137008.0000 - val_loss: 16999856.0000\n",
      "Epoch 45/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 17129782.0000 - val_loss: 16961574.0000\n",
      "Epoch 46/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 16985444.0000 - val_loss: 16986334.0000\n",
      "Epoch 47/200\n",
      "1422/1422 [==============================] - 1s 925us/step - loss: 16986790.0000 - val_loss: 16895990.0000\n",
      "Epoch 48/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 16989626.0000 - val_loss: 16790066.0000\n",
      "Epoch 49/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 17001390.0000 - val_loss: 16874548.0000\n",
      "Epoch 50/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 16918414.0000 - val_loss: 16949088.0000\n",
      "Epoch 51/200\n",
      "1422/1422 [==============================] - 1s 926us/step - loss: 16874776.0000 - val_loss: 16835662.0000\n",
      "Epoch 52/200\n",
      "1422/1422 [==============================] - 1s 926us/step - loss: 16863700.0000 - val_loss: 16682029.0000\n",
      "Epoch 53/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 16921570.0000 - val_loss: 16679529.0000\n",
      "Epoch 54/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 16867350.0000 - val_loss: 16640523.0000\n",
      "Epoch 55/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 16771269.0000 - val_loss: 16601075.0000\n",
      "Epoch 56/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 16729320.0000 - val_loss: 16570020.0000\n",
      "Epoch 57/200\n",
      "1422/1422 [==============================] - 1s 925us/step - loss: 16812576.0000 - val_loss: 16694049.0000\n",
      "Epoch 58/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 16808864.0000 - val_loss: 16516043.0000\n",
      "Epoch 59/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 16612571.0000 - val_loss: 16492492.0000\n",
      "Epoch 60/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 16722222.0000 - val_loss: 16688368.0000\n",
      "Epoch 61/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 16718419.0000 - val_loss: 16485006.0000\n",
      "Epoch 62/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 16701252.0000 - val_loss: 16507458.0000\n",
      "Epoch 63/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 16667365.0000 - val_loss: 16443350.0000\n",
      "Epoch 64/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 16685525.0000 - val_loss: 16378908.0000\n",
      "Epoch 65/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 16575915.0000 - val_loss: 16420080.0000\n",
      "Epoch 66/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 16661468.0000 - val_loss: 16302423.0000\n",
      "Epoch 67/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 16699039.0000 - val_loss: 16475619.0000\n",
      "Epoch 68/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16583402.0000 - val_loss: 16476214.0000\n",
      "Epoch 69/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16506551.0000 - val_loss: 16423891.0000\n",
      "Epoch 70/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16617691.0000 - val_loss: 16557887.0000\n",
      "Epoch 71/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16535495.0000 - val_loss: 16398799.0000\n",
      "Epoch 72/200\n",
      "1422/1422 [==============================] - 1s 908us/step - loss: 16556669.0000 - val_loss: 16428045.0000\n",
      "Epoch 73/200\n",
      "1422/1422 [==============================] - 1s 909us/step - loss: 16543183.0000 - val_loss: 16344472.0000\n",
      "Epoch 74/200\n",
      "1422/1422 [==============================] - 1s 907us/step - loss: 16534553.0000 - val_loss: 16435133.0000\n",
      "Epoch 75/200\n",
      "1422/1422 [==============================] - 1s 909us/step - loss: 16587922.0000 - val_loss: 16280867.0000\n",
      "Epoch 76/200\n",
      "1422/1422 [==============================] - 1s 909us/step - loss: 16479590.0000 - val_loss: 16258739.0000\n",
      "Epoch 77/200\n",
      "1422/1422 [==============================] - 1s 907us/step - loss: 16584305.0000 - val_loss: 16502005.0000\n",
      "Epoch 78/200\n",
      "1422/1422 [==============================] - 1s 907us/step - loss: 16508482.0000 - val_loss: 16252281.0000\n",
      "Epoch 79/200\n",
      "1422/1422 [==============================] - 1s 908us/step - loss: 16587993.0000 - val_loss: 16177693.0000\n",
      "Epoch 80/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16599648.0000 - val_loss: 16139611.0000\n",
      "Epoch 81/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16448368.0000 - val_loss: 16120243.0000\n",
      "Epoch 82/200\n",
      "1422/1422 [==============================] - 1s 925us/step - loss: 16527443.0000 - val_loss: 16170106.0000\n",
      "Epoch 83/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 16563923.0000 - val_loss: 16383481.0000\n",
      "Epoch 84/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 16469324.0000 - val_loss: 16141006.0000\n",
      "Epoch 85/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 16446134.0000 - val_loss: 16143071.0000\n",
      "Epoch 86/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 16542335.0000 - val_loss: 16664482.0000\n",
      "Epoch 87/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 16405327.0000 - val_loss: 16358399.0000\n",
      "Epoch 88/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 16506839.0000 - val_loss: 16110706.0000\n",
      "Epoch 89/200\n",
      "1422/1422 [==============================] - 1s 925us/step - loss: 16601496.0000 - val_loss: 16150625.0000\n",
      "Epoch 90/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 16424491.0000 - val_loss: 16162021.0000\n",
      "Epoch 91/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 16444692.0000 - val_loss: 16304327.0000\n",
      "Epoch 92/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 16463029.0000 - val_loss: 16256432.0000\n",
      "Epoch 93/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 16399445.0000 - val_loss: 16182087.0000\n",
      "Epoch 94/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 16456607.0000 - val_loss: 16225032.0000\n",
      "Epoch 95/200\n",
      "1422/1422 [==============================] - 1s 907us/step - loss: 16427823.0000 - val_loss: 16034745.0000\n",
      "Epoch 96/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16342302.0000 - val_loss: 16218796.0000\n",
      "Epoch 97/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 16564250.0000 - val_loss: 16059869.0000\n",
      "Epoch 98/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16438438.0000 - val_loss: 15993642.0000\n",
      "Epoch 99/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 16376954.0000 - val_loss: 16016637.0000\n",
      "Epoch 100/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 16440296.0000 - val_loss: 16052719.0000\n",
      "Epoch 101/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16312973.0000 - val_loss: 15995160.0000\n",
      "Epoch 102/200\n",
      "1422/1422 [==============================] - 1s 908us/step - loss: 16484900.0000 - val_loss: 15989907.0000\n",
      "Epoch 103/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16289010.0000 - val_loss: 16073374.0000\n",
      "Epoch 104/200\n",
      "1422/1422 [==============================] - 1s 906us/step - loss: 16265374.0000 - val_loss: 16144073.0000\n",
      "Epoch 105/200\n",
      "1422/1422 [==============================] - 1s 930us/step - loss: 16357551.0000 - val_loss: 16003732.0000\n",
      "Epoch 106/200\n",
      "1422/1422 [==============================] - 1s 929us/step - loss: 16278579.0000 - val_loss: 15946040.0000\n",
      "Epoch 107/200\n",
      "1422/1422 [==============================] - 1s 929us/step - loss: 16442478.0000 - val_loss: 15969591.0000\n",
      "Epoch 108/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 16301544.0000 - val_loss: 16025918.0000\n",
      "Epoch 109/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 16319599.0000 - val_loss: 16182243.0000\n",
      "Epoch 110/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 16397578.0000 - val_loss: 15994005.0000\n",
      "Epoch 111/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 16282144.0000 - val_loss: 16004415.0000\n",
      "Epoch 112/200\n",
      "1422/1422 [==============================] - 1s 915us/step - loss: 16278686.0000 - val_loss: 15950214.0000\n",
      "Epoch 113/200\n",
      "1422/1422 [==============================] - 1s 916us/step - loss: 16216190.0000 - val_loss: 15943242.0000\n",
      "Epoch 114/200\n",
      "1422/1422 [==============================] - 1s 928us/step - loss: 16389973.0000 - val_loss: 15998705.0000\n",
      "Epoch 115/200\n",
      "1422/1422 [==============================] - 1s 932us/step - loss: 16206563.0000 - val_loss: 16072958.0000\n",
      "Epoch 116/200\n",
      "1422/1422 [==============================] - 1s 927us/step - loss: 16173366.0000 - val_loss: 15997331.0000\n",
      "Epoch 117/200\n",
      "1422/1422 [==============================] - 1s 925us/step - loss: 16235262.0000 - val_loss: 15897990.0000\n",
      "Epoch 118/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 16200851.0000 - val_loss: 15893224.0000\n",
      "Epoch 119/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 16220530.0000 - val_loss: 15907261.0000\n",
      "Epoch 120/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 16117078.0000 - val_loss: 15877566.0000\n",
      "Epoch 121/200\n",
      "1422/1422 [==============================] - 1s 909us/step - loss: 16202037.0000 - val_loss: 15991406.0000\n",
      "Epoch 122/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 16211737.0000 - val_loss: 15900133.0000\n",
      "Epoch 123/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 16385216.0000 - val_loss: 15792613.0000\n",
      "Epoch 124/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 16362004.0000 - val_loss: 15881184.0000\n",
      "Epoch 125/200\n",
      "1422/1422 [==============================] - 1s 910us/step - loss: 16255596.0000 - val_loss: 15972283.0000\n",
      "Epoch 126/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 16293308.0000 - val_loss: 15872952.0000\n",
      "Epoch 127/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 16373508.0000 - val_loss: 15933989.0000\n",
      "Epoch 128/200\n",
      "1422/1422 [==============================] - 1s 916us/step - loss: 16179774.0000 - val_loss: 15993273.0000\n",
      "Epoch 129/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 16265113.0000 - val_loss: 15881398.0000\n",
      "Epoch 130/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 16224281.0000 - val_loss: 15951084.0000\n",
      "Epoch 131/200\n",
      "1422/1422 [==============================] - 1s 915us/step - loss: 16158331.0000 - val_loss: 15930328.0000\n",
      "Epoch 132/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 16257068.0000 - val_loss: 15952533.0000\n",
      "Epoch 133/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 16192891.0000 - val_loss: 15850292.0000\n",
      "1219/1219 [==============================] - 0s 353us/step\n",
      "\n",
      "üîÅ Running combo 3/5: [128, 128, 64, 32], relu, dropout=0.05, l2=0.0005\n",
      "Epoch 1/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 116171704.0000 - val_loss: 57330780.0000\n",
      "Epoch 2/200\n",
      "1422/1422 [==============================] - 1s 959us/step - loss: 50877076.0000 - val_loss: 51215540.0000\n",
      "Epoch 3/200\n",
      "1422/1422 [==============================] - 1s 951us/step - loss: 45984380.0000 - val_loss: 46583940.0000\n",
      "Epoch 4/200\n",
      "1422/1422 [==============================] - 1s 949us/step - loss: 42086204.0000 - val_loss: 43001168.0000\n",
      "Epoch 5/200\n",
      "1422/1422 [==============================] - 1s 959us/step - loss: 38569744.0000 - val_loss: 39359600.0000\n",
      "Epoch 6/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 35919916.0000 - val_loss: 36763856.0000\n",
      "Epoch 7/200\n",
      "1422/1422 [==============================] - 1s 915us/step - loss: 33128888.0000 - val_loss: 33621528.0000\n",
      "Epoch 8/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 29541892.0000 - val_loss: 28463196.0000\n",
      "Epoch 9/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 25567290.0000 - val_loss: 23644048.0000\n",
      "Epoch 10/200\n",
      "1422/1422 [==============================] - 1s 911us/step - loss: 22838948.0000 - val_loss: 21085084.0000\n",
      "Epoch 11/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 21569610.0000 - val_loss: 20092290.0000\n",
      "Epoch 12/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 20681094.0000 - val_loss: 19463048.0000\n",
      "Epoch 13/200\n",
      "1422/1422 [==============================] - 1s 915us/step - loss: 20151850.0000 - val_loss: 18816408.0000\n",
      "Epoch 14/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 20147466.0000 - val_loss: 18371070.0000\n",
      "Epoch 15/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 19746008.0000 - val_loss: 18357888.0000\n",
      "Epoch 16/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 19692212.0000 - val_loss: 17744058.0000\n",
      "Epoch 17/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 19535276.0000 - val_loss: 17612298.0000\n",
      "Epoch 18/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 19454638.0000 - val_loss: 17306116.0000\n",
      "Epoch 19/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 19181136.0000 - val_loss: 17123722.0000\n",
      "Epoch 20/200\n",
      "1422/1422 [==============================] - 1s 913us/step - loss: 19296170.0000 - val_loss: 16945642.0000\n",
      "Epoch 21/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 19185048.0000 - val_loss: 17792230.0000\n",
      "Epoch 22/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 19107134.0000 - val_loss: 17473434.0000\n",
      "Epoch 23/200\n",
      "1422/1422 [==============================] - 1s 898us/step - loss: 18962642.0000 - val_loss: 16784766.0000\n",
      "Epoch 24/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 18896852.0000 - val_loss: 16770884.0000\n",
      "Epoch 25/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 18684054.0000 - val_loss: 16839676.0000\n",
      "Epoch 26/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 18877242.0000 - val_loss: 16661369.0000\n",
      "Epoch 27/200\n",
      "1422/1422 [==============================] - 1s 897us/step - loss: 18716552.0000 - val_loss: 16886196.0000\n",
      "Epoch 28/200\n",
      "1422/1422 [==============================] - 1s 896us/step - loss: 18779498.0000 - val_loss: 16474226.0000\n",
      "Epoch 29/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 18974764.0000 - val_loss: 16668742.0000\n",
      "Epoch 30/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 18619212.0000 - val_loss: 16792586.0000\n",
      "Epoch 31/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 18754426.0000 - val_loss: 16678683.0000\n",
      "Epoch 32/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 18546190.0000 - val_loss: 16380970.0000\n",
      "Epoch 33/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 18630238.0000 - val_loss: 16601411.0000\n",
      "Epoch 34/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 18549898.0000 - val_loss: 16701344.0000\n",
      "Epoch 35/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 18634288.0000 - val_loss: 16423039.0000\n",
      "Epoch 36/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 18383468.0000 - val_loss: 16292246.0000\n",
      "Epoch 37/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 18413302.0000 - val_loss: 16695368.0000\n",
      "Epoch 38/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 18478976.0000 - val_loss: 16504995.0000\n",
      "Epoch 39/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 18498816.0000 - val_loss: 16665995.0000\n",
      "Epoch 40/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 18399866.0000 - val_loss: 16279826.0000\n",
      "Epoch 41/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 18455482.0000 - val_loss: 16284483.0000\n",
      "Epoch 42/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 18397256.0000 - val_loss: 16446511.0000\n",
      "Epoch 43/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 18483030.0000 - val_loss: 16301021.0000\n",
      "Epoch 44/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 18529926.0000 - val_loss: 16177486.0000\n",
      "Epoch 45/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 18331584.0000 - val_loss: 16019722.0000\n",
      "Epoch 46/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 18235388.0000 - val_loss: 16071770.0000\n",
      "Epoch 47/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 18388378.0000 - val_loss: 15938727.0000\n",
      "Epoch 48/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 18349530.0000 - val_loss: 16172522.0000\n",
      "Epoch 49/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 18381078.0000 - val_loss: 15969137.0000\n",
      "Epoch 50/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 18292788.0000 - val_loss: 15958239.0000\n",
      "Epoch 51/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 18282084.0000 - val_loss: 16276202.0000\n",
      "Epoch 52/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 18150064.0000 - val_loss: 16499343.0000\n",
      "Epoch 53/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 18405144.0000 - val_loss: 16001681.0000\n",
      "Epoch 54/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 18209760.0000 - val_loss: 16063589.0000\n",
      "Epoch 55/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 18310896.0000 - val_loss: 15911627.0000\n",
      "Epoch 56/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 18035140.0000 - val_loss: 16497811.0000\n",
      "Epoch 57/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 18072132.0000 - val_loss: 16250340.0000\n",
      "Epoch 58/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 18081634.0000 - val_loss: 15818844.0000\n",
      "Epoch 59/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 18104288.0000 - val_loss: 15914935.0000\n",
      "Epoch 60/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 18232884.0000 - val_loss: 15988267.0000\n",
      "Epoch 61/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 18158628.0000 - val_loss: 15738286.0000\n",
      "Epoch 62/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 18048238.0000 - val_loss: 16122229.0000\n",
      "Epoch 63/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 17826870.0000 - val_loss: 15966104.0000\n",
      "Epoch 64/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 17864250.0000 - val_loss: 15608232.0000\n",
      "Epoch 65/200\n",
      "1422/1422 [==============================] - 1s 897us/step - loss: 17780720.0000 - val_loss: 15487644.0000\n",
      "Epoch 66/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 17925184.0000 - val_loss: 15452809.0000\n",
      "Epoch 67/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 17899230.0000 - val_loss: 15411884.0000\n",
      "Epoch 68/200\n",
      "1422/1422 [==============================] - 1s 914us/step - loss: 17806430.0000 - val_loss: 15624634.0000\n",
      "Epoch 69/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 17645702.0000 - val_loss: 15277547.0000\n",
      "Epoch 70/200\n",
      "1422/1422 [==============================] - 1s 916us/step - loss: 17782098.0000 - val_loss: 15246312.0000\n",
      "Epoch 71/200\n",
      "1422/1422 [==============================] - 1s 915us/step - loss: 17647402.0000 - val_loss: 15563459.0000\n",
      "Epoch 72/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 17546756.0000 - val_loss: 15324117.0000\n",
      "Epoch 73/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 17443748.0000 - val_loss: 15374835.0000\n",
      "Epoch 74/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 17352760.0000 - val_loss: 15207536.0000\n",
      "Epoch 75/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 17425046.0000 - val_loss: 15372143.0000\n",
      "Epoch 76/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 17172508.0000 - val_loss: 14862960.0000\n",
      "Epoch 77/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 17117496.0000 - val_loss: 14627198.0000\n",
      "Epoch 78/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 17146298.0000 - val_loss: 14538447.0000\n",
      "Epoch 79/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 16813100.0000 - val_loss: 13928805.0000\n",
      "Epoch 80/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 16762536.0000 - val_loss: 13925072.0000\n",
      "Epoch 81/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 16646485.0000 - val_loss: 13766796.0000\n",
      "Epoch 82/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 16546266.0000 - val_loss: 14097131.0000\n",
      "Epoch 83/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 16408241.0000 - val_loss: 13683743.0000\n",
      "Epoch 84/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 16295819.0000 - val_loss: 13003953.0000\n",
      "Epoch 85/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 16066355.0000 - val_loss: 12886129.0000\n",
      "Epoch 86/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 16016597.0000 - val_loss: 14197370.0000\n",
      "Epoch 87/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 15868222.0000 - val_loss: 13362710.0000\n",
      "Epoch 88/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 15775015.0000 - val_loss: 12145794.0000\n",
      "Epoch 89/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 15509352.0000 - val_loss: 11988840.0000\n",
      "Epoch 90/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 15247004.0000 - val_loss: 11824497.0000\n",
      "Epoch 91/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 15296980.0000 - val_loss: 11955175.0000\n",
      "Epoch 92/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 15181494.0000 - val_loss: 11301329.0000\n",
      "Epoch 93/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 15075148.0000 - val_loss: 11586786.0000\n",
      "Epoch 94/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 14952901.0000 - val_loss: 11323944.0000\n",
      "Epoch 95/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 14817249.0000 - val_loss: 10641707.0000\n",
      "Epoch 96/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 14713924.0000 - val_loss: 11149379.0000\n",
      "Epoch 97/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 14773551.0000 - val_loss: 10366520.0000\n",
      "Epoch 98/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 14453644.0000 - val_loss: 10390721.0000\n",
      "Epoch 99/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 14416291.0000 - val_loss: 10095147.0000\n",
      "Epoch 100/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 14318668.0000 - val_loss: 9744313.0000\n",
      "Epoch 101/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 14263183.0000 - val_loss: 9380201.0000\n",
      "Epoch 102/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 14389570.0000 - val_loss: 9323266.0000\n",
      "Epoch 103/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 14090554.0000 - val_loss: 10207021.0000\n",
      "Epoch 104/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 14183098.0000 - val_loss: 9058469.0000\n",
      "Epoch 105/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 14044636.0000 - val_loss: 9072065.0000\n",
      "Epoch 106/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 14157926.0000 - val_loss: 8808120.0000\n",
      "Epoch 107/200\n",
      "1422/1422 [==============================] - 1s 897us/step - loss: 14026376.0000 - val_loss: 8768004.0000\n",
      "Epoch 108/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 13840800.0000 - val_loss: 8981396.0000\n",
      "Epoch 109/200\n",
      "1422/1422 [==============================] - 1s 897us/step - loss: 13823406.0000 - val_loss: 9484177.0000\n",
      "Epoch 110/200\n",
      "1422/1422 [==============================] - 1s 896us/step - loss: 13805141.0000 - val_loss: 8285028.5000\n",
      "Epoch 111/200\n",
      "1422/1422 [==============================] - 1s 895us/step - loss: 13643539.0000 - val_loss: 8812165.0000\n",
      "Epoch 112/200\n",
      "1422/1422 [==============================] - 1s 898us/step - loss: 13731235.0000 - val_loss: 8408261.0000\n",
      "Epoch 113/200\n",
      "1422/1422 [==============================] - 1s 896us/step - loss: 13634807.0000 - val_loss: 8216020.0000\n",
      "Epoch 114/200\n",
      "1422/1422 [==============================] - 1s 896us/step - loss: 13524481.0000 - val_loss: 8376317.5000\n",
      "Epoch 115/200\n",
      "1422/1422 [==============================] - 1s 896us/step - loss: 13597326.0000 - val_loss: 8109689.5000\n",
      "Epoch 116/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 13550602.0000 - val_loss: 8150995.5000\n",
      "Epoch 117/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 13558639.0000 - val_loss: 9203415.0000\n",
      "Epoch 118/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 13399038.0000 - val_loss: 7904084.5000\n",
      "Epoch 119/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 13402805.0000 - val_loss: 7985860.0000\n",
      "Epoch 120/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 13473915.0000 - val_loss: 7861979.0000\n",
      "Epoch 121/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 13295215.0000 - val_loss: 8671292.0000\n",
      "Epoch 122/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 13350086.0000 - val_loss: 8300079.0000\n",
      "Epoch 123/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 13268146.0000 - val_loss: 8125595.0000\n",
      "Epoch 124/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 13228783.0000 - val_loss: 7795357.5000\n",
      "Epoch 125/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 13239740.0000 - val_loss: 8006852.5000\n",
      "Epoch 126/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 13149329.0000 - val_loss: 8283591.0000\n",
      "Epoch 127/200\n",
      "1422/1422 [==============================] - 1s 923us/step - loss: 13169030.0000 - val_loss: 7681796.5000\n",
      "Epoch 128/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 13407139.0000 - val_loss: 8207961.5000\n",
      "Epoch 129/200\n",
      "1422/1422 [==============================] - 1s 920us/step - loss: 13176906.0000 - val_loss: 7940478.0000\n",
      "Epoch 130/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 13107148.0000 - val_loss: 7341946.0000\n",
      "Epoch 131/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 13200240.0000 - val_loss: 8420348.0000\n",
      "Epoch 132/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 13173988.0000 - val_loss: 7765623.0000\n",
      "Epoch 133/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 13203773.0000 - val_loss: 7219154.0000\n",
      "Epoch 134/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 13290551.0000 - val_loss: 9679114.0000\n",
      "Epoch 135/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 12920418.0000 - val_loss: 7291905.0000\n",
      "Epoch 136/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 12890927.0000 - val_loss: 7236779.0000\n",
      "Epoch 137/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 13017658.0000 - val_loss: 6980231.5000\n",
      "Epoch 138/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 12953203.0000 - val_loss: 7218648.5000\n",
      "Epoch 139/200\n",
      "1422/1422 [==============================] - 1s 905us/step - loss: 13030071.0000 - val_loss: 7170067.5000\n",
      "Epoch 140/200\n",
      "1422/1422 [==============================] - 1s 904us/step - loss: 12981777.0000 - val_loss: 6927517.5000\n",
      "Epoch 141/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 12897066.0000 - val_loss: 6800685.5000\n",
      "Epoch 142/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 12854487.0000 - val_loss: 7010701.5000\n",
      "Epoch 143/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 12877611.0000 - val_loss: 7168588.0000\n",
      "Epoch 144/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 12793334.0000 - val_loss: 6760629.0000\n",
      "Epoch 145/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 12807601.0000 - val_loss: 6917121.5000\n",
      "Epoch 146/200\n",
      "1422/1422 [==============================] - 1s 907us/step - loss: 12862280.0000 - val_loss: 6574960.0000\n",
      "Epoch 147/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 12790497.0000 - val_loss: 6981931.0000\n",
      "Epoch 148/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 12806410.0000 - val_loss: 6697409.0000\n",
      "Epoch 149/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 12708535.0000 - val_loss: 6797594.5000\n",
      "Epoch 150/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 12758396.0000 - val_loss: 6330446.0000\n",
      "Epoch 151/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 12792820.0000 - val_loss: 7597908.0000\n",
      "Epoch 152/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 12779879.0000 - val_loss: 7948081.0000\n",
      "Epoch 153/200\n",
      "1422/1422 [==============================] - 1s 922us/step - loss: 12567108.0000 - val_loss: 6608145.5000\n",
      "Epoch 154/200\n",
      "1422/1422 [==============================] - 1s 924us/step - loss: 12714855.0000 - val_loss: 8134516.5000\n",
      "Epoch 155/200\n",
      "1422/1422 [==============================] - 1s 921us/step - loss: 12754498.0000 - val_loss: 7146317.0000\n",
      "Epoch 156/200\n",
      "1422/1422 [==============================] - 1s 912us/step - loss: 12620013.0000 - val_loss: 6594351.0000\n",
      "Epoch 157/200\n",
      "1422/1422 [==============================] - 1s 900us/step - loss: 12576278.0000 - val_loss: 6952101.0000\n",
      "Epoch 158/200\n",
      "1422/1422 [==============================] - 1s 899us/step - loss: 12648439.0000 - val_loss: 8221794.5000\n",
      "Epoch 159/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 12683116.0000 - val_loss: 6198902.5000\n",
      "Epoch 160/200\n",
      "1422/1422 [==============================] - 1s 898us/step - loss: 12455318.0000 - val_loss: 7849772.5000\n",
      "Epoch 161/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 12549090.0000 - val_loss: 6610344.0000\n",
      "Epoch 162/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 12412050.0000 - val_loss: 6893445.0000\n",
      "Epoch 163/200\n",
      "1422/1422 [==============================] - 1s 918us/step - loss: 12525651.0000 - val_loss: 6570326.0000\n",
      "Epoch 164/200\n",
      "1422/1422 [==============================] - 1s 901us/step - loss: 12575860.0000 - val_loss: 7997936.0000\n",
      "Epoch 165/200\n",
      "1422/1422 [==============================] - 1s 902us/step - loss: 12373115.0000 - val_loss: 6901463.0000\n",
      "Epoch 166/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 12534996.0000 - val_loss: 6643865.5000\n",
      "Epoch 167/200\n",
      "1422/1422 [==============================] - 1s 919us/step - loss: 12484363.0000 - val_loss: 6646512.0000\n",
      "Epoch 168/200\n",
      "1422/1422 [==============================] - 1s 917us/step - loss: 12432673.0000 - val_loss: 6745516.0000\n",
      "Epoch 169/200\n",
      "1422/1422 [==============================] - 1s 903us/step - loss: 12387560.0000 - val_loss: 6604600.0000\n",
      "1219/1219 [==============================] - 0s 345us/step\n",
      "\n",
      "üîÅ Running combo 4/5: [238, 128, 64, 32], relu, dropout=0.1, l2=0.0005\n",
      "Epoch 1/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 112346024.0000 - val_loss: 56801544.0000\n",
      "Epoch 2/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 51806648.0000 - val_loss: 50740568.0000\n",
      "Epoch 3/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 47253208.0000 - val_loss: 46109928.0000\n",
      "Epoch 4/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 43429856.0000 - val_loss: 42186180.0000\n",
      "Epoch 5/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 39463688.0000 - val_loss: 38753016.0000\n",
      "Epoch 6/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 36656092.0000 - val_loss: 35716620.0000\n",
      "Epoch 7/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 33548388.0000 - val_loss: 31453288.0000\n",
      "Epoch 8/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 29765506.0000 - val_loss: 26173708.0000\n",
      "Epoch 9/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 26873284.0000 - val_loss: 23639656.0000\n",
      "Epoch 10/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 24561394.0000 - val_loss: 20835576.0000\n",
      "Epoch 11/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 23741514.0000 - val_loss: 20260462.0000\n",
      "Epoch 12/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 23115260.0000 - val_loss: 19984824.0000\n",
      "Epoch 13/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 22706082.0000 - val_loss: 18784082.0000\n",
      "Epoch 14/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 22553662.0000 - val_loss: 18230306.0000\n",
      "Epoch 15/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 22312214.0000 - val_loss: 18294124.0000\n",
      "Epoch 16/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 22191484.0000 - val_loss: 17898792.0000\n",
      "Epoch 17/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 22074680.0000 - val_loss: 17695830.0000\n",
      "Epoch 18/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21918006.0000 - val_loss: 17441478.0000\n",
      "Epoch 19/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21657904.0000 - val_loss: 17408968.0000\n",
      "Epoch 20/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21688156.0000 - val_loss: 16880836.0000\n",
      "Epoch 21/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21706882.0000 - val_loss: 17267382.0000\n",
      "Epoch 22/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21421472.0000 - val_loss: 17498654.0000\n",
      "Epoch 23/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21135570.0000 - val_loss: 16635082.0000\n",
      "Epoch 24/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21380108.0000 - val_loss: 16794714.0000\n",
      "Epoch 25/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21329806.0000 - val_loss: 17355044.0000\n",
      "Epoch 26/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21249330.0000 - val_loss: 16588067.0000\n",
      "Epoch 27/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21192384.0000 - val_loss: 16558974.0000\n",
      "Epoch 28/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21180986.0000 - val_loss: 16864252.0000\n",
      "Epoch 29/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 21234716.0000 - val_loss: 16171796.0000\n",
      "Epoch 30/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 20985442.0000 - val_loss: 16267003.0000\n",
      "Epoch 31/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 21051588.0000 - val_loss: 16459944.0000\n",
      "Epoch 32/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 20891012.0000 - val_loss: 16143471.0000\n",
      "Epoch 33/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 20878818.0000 - val_loss: 16178862.0000\n",
      "Epoch 34/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 20863062.0000 - val_loss: 16198570.0000\n",
      "Epoch 35/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 20806206.0000 - val_loss: 17029286.0000\n",
      "Epoch 36/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20663744.0000 - val_loss: 16123830.0000\n",
      "Epoch 37/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 20650712.0000 - val_loss: 16579806.0000\n",
      "Epoch 38/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 20730914.0000 - val_loss: 15978599.0000\n",
      "Epoch 39/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 20605762.0000 - val_loss: 15769029.0000\n",
      "Epoch 40/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 20572850.0000 - val_loss: 16030272.0000\n",
      "Epoch 41/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20497540.0000 - val_loss: 15825262.0000\n",
      "Epoch 42/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20559154.0000 - val_loss: 15802434.0000\n",
      "Epoch 43/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 20605884.0000 - val_loss: 16481652.0000\n",
      "Epoch 44/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20509018.0000 - val_loss: 15455404.0000\n",
      "Epoch 45/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 20260644.0000 - val_loss: 15313064.0000\n",
      "Epoch 46/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20277542.0000 - val_loss: 15653801.0000\n",
      "Epoch 47/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20390552.0000 - val_loss: 15367698.0000\n",
      "Epoch 48/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 20235854.0000 - val_loss: 15400416.0000\n",
      "Epoch 49/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20082052.0000 - val_loss: 15895127.0000\n",
      "Epoch 50/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 20031916.0000 - val_loss: 14932719.0000\n",
      "Epoch 51/200\n",
      "1422/1422 [==============================] - 1s 998us/step - loss: 20179402.0000 - val_loss: 15635276.0000\n",
      "Epoch 52/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20056048.0000 - val_loss: 15042166.0000\n",
      "Epoch 53/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 20075670.0000 - val_loss: 14759631.0000\n",
      "Epoch 54/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19805196.0000 - val_loss: 14461782.0000\n",
      "Epoch 55/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 19750114.0000 - val_loss: 14603167.0000\n",
      "Epoch 56/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 19641176.0000 - val_loss: 14658298.0000\n",
      "Epoch 57/200\n",
      "1422/1422 [==============================] - 1s 998us/step - loss: 19668452.0000 - val_loss: 14701261.0000\n",
      "Epoch 58/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19436090.0000 - val_loss: 13915264.0000\n",
      "Epoch 59/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19392738.0000 - val_loss: 14206195.0000\n",
      "Epoch 60/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19507216.0000 - val_loss: 13811222.0000\n",
      "Epoch 61/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19277556.0000 - val_loss: 13405645.0000\n",
      "Epoch 62/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19159974.0000 - val_loss: 13452770.0000\n",
      "Epoch 63/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19001670.0000 - val_loss: 13442310.0000\n",
      "Epoch 64/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 19062742.0000 - val_loss: 13361301.0000\n",
      "Epoch 65/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 18706266.0000 - val_loss: 12795550.0000\n",
      "Epoch 66/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 18861152.0000 - val_loss: 12512583.0000\n",
      "Epoch 67/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 18906206.0000 - val_loss: 12360035.0000\n",
      "Epoch 68/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 18620962.0000 - val_loss: 12432278.0000\n",
      "Epoch 69/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 18459708.0000 - val_loss: 12499979.0000\n",
      "Epoch 70/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 18624504.0000 - val_loss: 12101098.0000\n",
      "Epoch 71/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 18377578.0000 - val_loss: 12000485.0000\n",
      "Epoch 72/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 18329146.0000 - val_loss: 11823290.0000\n",
      "Epoch 73/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 18222250.0000 - val_loss: 12433833.0000\n",
      "Epoch 74/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 18124618.0000 - val_loss: 11668106.0000\n",
      "Epoch 75/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 18036896.0000 - val_loss: 11137502.0000\n",
      "Epoch 76/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 17979032.0000 - val_loss: 10950982.0000\n",
      "Epoch 77/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17770832.0000 - val_loss: 10344786.0000\n",
      "Epoch 78/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 17590140.0000 - val_loss: 10015575.0000\n",
      "Epoch 79/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17628082.0000 - val_loss: 10713753.0000\n",
      "Epoch 80/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17526404.0000 - val_loss: 9736145.0000\n",
      "Epoch 81/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17571788.0000 - val_loss: 9292411.0000\n",
      "Epoch 82/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17806456.0000 - val_loss: 9798067.0000\n",
      "Epoch 83/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17323352.0000 - val_loss: 9512171.0000\n",
      "Epoch 84/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17298568.0000 - val_loss: 9553698.0000\n",
      "Epoch 85/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 17109562.0000 - val_loss: 8848345.0000\n",
      "Epoch 86/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 17243488.0000 - val_loss: 10189242.0000\n",
      "Epoch 87/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17196196.0000 - val_loss: 9041666.0000\n",
      "Epoch 88/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17123660.0000 - val_loss: 9032522.0000\n",
      "Epoch 89/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17247400.0000 - val_loss: 8315868.0000\n",
      "Epoch 90/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17074562.0000 - val_loss: 8245682.5000\n",
      "Epoch 91/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17040870.0000 - val_loss: 10888005.0000\n",
      "Epoch 92/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17012420.0000 - val_loss: 8370580.5000\n",
      "Epoch 93/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17034616.0000 - val_loss: 8491679.0000\n",
      "Epoch 94/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16920334.0000 - val_loss: 7833547.5000\n",
      "Epoch 95/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 16959648.0000 - val_loss: 8164230.5000\n",
      "Epoch 96/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 17044324.0000 - val_loss: 8347485.0000\n",
      "Epoch 97/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16975790.0000 - val_loss: 8529030.0000\n",
      "Epoch 98/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16888098.0000 - val_loss: 8352181.5000\n",
      "Epoch 99/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16795564.0000 - val_loss: 7753533.0000\n",
      "Epoch 100/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16618831.0000 - val_loss: 8496351.0000\n",
      "Epoch 101/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16876710.0000 - val_loss: 7557729.0000\n",
      "Epoch 102/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 16716436.0000 - val_loss: 7945603.0000\n",
      "Epoch 103/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 16718738.0000 - val_loss: 7893816.0000\n",
      "Epoch 104/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16652335.0000 - val_loss: 7441682.5000\n",
      "Epoch 105/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16581262.0000 - val_loss: 8322510.5000\n",
      "Epoch 106/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16863278.0000 - val_loss: 8101978.0000\n",
      "Epoch 107/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16620618.0000 - val_loss: 7584945.0000\n",
      "Epoch 108/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 16738001.0000 - val_loss: 7624759.0000\n",
      "Epoch 109/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 16614716.0000 - val_loss: 7763560.0000\n",
      "Epoch 110/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16567834.0000 - val_loss: 9307093.0000\n",
      "Epoch 111/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16697228.0000 - val_loss: 7362780.5000\n",
      "Epoch 112/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16473691.0000 - val_loss: 7372124.5000\n",
      "Epoch 113/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 16355733.0000 - val_loss: 7290562.5000\n",
      "Epoch 114/200\n",
      "1422/1422 [==============================] - 1s 998us/step - loss: 16511961.0000 - val_loss: 7233642.5000\n",
      "Epoch 115/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 16747350.0000 - val_loss: 7090833.0000\n",
      "Epoch 116/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 16649153.0000 - val_loss: 7223669.5000\n",
      "Epoch 117/200\n",
      "1422/1422 [==============================] - 1s 998us/step - loss: 16382068.0000 - val_loss: 7164692.0000\n",
      "Epoch 118/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16346827.0000 - val_loss: 7506810.0000\n",
      "Epoch 119/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16515243.0000 - val_loss: 7428794.5000\n",
      "Epoch 120/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16578819.0000 - val_loss: 6431518.5000\n",
      "Epoch 121/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16285480.0000 - val_loss: 7507859.0000\n",
      "Epoch 122/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 16113058.0000 - val_loss: 7114530.0000\n",
      "Epoch 123/200\n",
      "1422/1422 [==============================] - 1s 998us/step - loss: 16404610.0000 - val_loss: 8647803.0000\n",
      "Epoch 124/200\n",
      "1422/1422 [==============================] - 1s 998us/step - loss: 16345111.0000 - val_loss: 7148164.5000\n",
      "Epoch 125/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16320983.0000 - val_loss: 6565334.5000\n",
      "Epoch 126/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 16406480.0000 - val_loss: 7447873.0000\n",
      "Epoch 127/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16394581.0000 - val_loss: 6910957.5000\n",
      "Epoch 128/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16380442.0000 - val_loss: 7935223.0000\n",
      "Epoch 129/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16286730.0000 - val_loss: 6405283.0000\n",
      "Epoch 130/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16377359.0000 - val_loss: 6542008.0000\n",
      "Epoch 131/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16337310.0000 - val_loss: 9638202.0000\n",
      "Epoch 132/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16262035.0000 - val_loss: 6657321.0000\n",
      "Epoch 133/200\n",
      "1422/1422 [==============================] - 1s 996us/step - loss: 16299091.0000 - val_loss: 7397940.0000\n",
      "Epoch 134/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16376555.0000 - val_loss: 7078164.5000\n",
      "Epoch 135/200\n",
      "1422/1422 [==============================] - 1s 999us/step - loss: 16255682.0000 - val_loss: 6745763.0000\n",
      "Epoch 136/200\n",
      "1422/1422 [==============================] - 1s 997us/step - loss: 16072193.0000 - val_loss: 6782092.5000\n",
      "Epoch 137/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16329957.0000 - val_loss: 7295192.0000\n",
      "Epoch 138/200\n",
      "1422/1422 [==============================] - 1s 1000us/step - loss: 16216186.0000 - val_loss: 6745895.0000\n",
      "Epoch 139/200\n",
      "1422/1422 [==============================] - 1s 1ms/step - loss: 16281539.0000 - val_loss: 6549588.5000\n",
      "1219/1219 [==============================] - 1s 353us/step\n",
      "\n",
      "üîÅ Running combo 5/5: [238, 238, 128, 64, 32], relu, dropout=0.05, l2=0.0001\n",
      "Epoch 1/200\n",
      "1422/1422 [==============================] - 3s 2ms/step - loss: 80193320.0000 - val_loss: 48226464.0000\n",
      "Epoch 2/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 40754372.0000 - val_loss: 38470448.0000\n",
      "Epoch 3/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 31961032.0000 - val_loss: 26898782.0000\n",
      "Epoch 4/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 23268780.0000 - val_loss: 20825704.0000\n",
      "Epoch 5/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 20789168.0000 - val_loss: 18517890.0000\n",
      "Epoch 6/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 20123988.0000 - val_loss: 18980824.0000\n",
      "Epoch 7/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 19816064.0000 - val_loss: 17154158.0000\n",
      "Epoch 8/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19716044.0000 - val_loss: 17407276.0000\n",
      "Epoch 9/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19357842.0000 - val_loss: 17374060.0000\n",
      "Epoch 10/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19076678.0000 - val_loss: 16867624.0000\n",
      "Epoch 11/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19057820.0000 - val_loss: 16240590.0000\n",
      "Epoch 12/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18641610.0000 - val_loss: 17909462.0000\n",
      "Epoch 13/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18631784.0000 - val_loss: 15880742.0000\n",
      "Epoch 14/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18497326.0000 - val_loss: 16075031.0000\n",
      "Epoch 15/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18332120.0000 - val_loss: 16636829.0000\n",
      "Epoch 16/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17939624.0000 - val_loss: 15309700.0000\n",
      "Epoch 17/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17791128.0000 - val_loss: 14741434.0000\n",
      "Epoch 18/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17628576.0000 - val_loss: 14231756.0000\n",
      "Epoch 19/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 17217796.0000 - val_loss: 14233586.0000\n",
      "Epoch 20/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16925004.0000 - val_loss: 14310585.0000\n",
      "Epoch 21/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16803022.0000 - val_loss: 13088259.0000\n",
      "Epoch 22/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16671618.0000 - val_loss: 13084917.0000\n",
      "Epoch 23/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16354299.0000 - val_loss: 13735929.0000\n",
      "Epoch 24/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16092742.0000 - val_loss: 12852010.0000\n",
      "Epoch 25/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15669087.0000 - val_loss: 11279490.0000\n",
      "Epoch 26/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15820043.0000 - val_loss: 11732499.0000\n",
      "Epoch 27/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15591733.0000 - val_loss: 11517955.0000\n",
      "Epoch 28/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15369003.0000 - val_loss: 11207958.0000\n",
      "Epoch 29/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15214263.0000 - val_loss: 11651054.0000\n",
      "Epoch 30/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15251210.0000 - val_loss: 9957493.0000\n",
      "Epoch 31/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15232050.0000 - val_loss: 11534340.0000\n",
      "Epoch 32/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14952776.0000 - val_loss: 9618278.0000\n",
      "Epoch 33/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14948924.0000 - val_loss: 9791703.0000\n",
      "Epoch 34/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14816606.0000 - val_loss: 9350250.0000\n",
      "Epoch 35/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15012359.0000 - val_loss: 10083211.0000\n",
      "Epoch 36/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14860962.0000 - val_loss: 11531024.0000\n",
      "Epoch 37/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14814610.0000 - val_loss: 10722646.0000\n",
      "Epoch 38/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14850515.0000 - val_loss: 9543197.0000\n",
      "Epoch 39/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14819023.0000 - val_loss: 10526131.0000\n",
      "Epoch 40/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14645625.0000 - val_loss: 9460938.0000\n",
      "Epoch 41/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14698283.0000 - val_loss: 9707639.0000\n",
      "Epoch 42/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14600715.0000 - val_loss: 9360575.0000\n",
      "Epoch 43/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14549825.0000 - val_loss: 9144477.0000\n",
      "Epoch 44/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14589937.0000 - val_loss: 10840642.0000\n",
      "Epoch 45/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14439525.0000 - val_loss: 9019431.0000\n",
      "Epoch 46/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14437519.0000 - val_loss: 9155748.0000\n",
      "Epoch 47/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14402379.0000 - val_loss: 9571206.0000\n",
      "Epoch 48/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14491667.0000 - val_loss: 9146672.0000\n",
      "Epoch 49/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14455422.0000 - val_loss: 10106280.0000\n",
      "Epoch 50/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14349902.0000 - val_loss: 9528313.0000\n",
      "Epoch 51/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14396996.0000 - val_loss: 8378934.0000\n",
      "Epoch 52/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14293219.0000 - val_loss: 9175742.0000\n",
      "Epoch 53/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14113212.0000 - val_loss: 8622305.0000\n",
      "Epoch 54/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14125079.0000 - val_loss: 8639832.0000\n",
      "Epoch 55/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14028449.0000 - val_loss: 8153975.0000\n",
      "Epoch 56/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13915780.0000 - val_loss: 8534074.0000\n",
      "Epoch 57/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13772823.0000 - val_loss: 8145013.0000\n",
      "Epoch 58/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14051784.0000 - val_loss: 8411353.0000\n",
      "Epoch 59/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13856789.0000 - val_loss: 8101227.5000\n",
      "Epoch 60/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13705534.0000 - val_loss: 7525825.0000\n",
      "Epoch 61/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13814179.0000 - val_loss: 8586249.0000\n",
      "Epoch 62/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13451044.0000 - val_loss: 7830735.5000\n",
      "Epoch 63/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13475750.0000 - val_loss: 7259636.0000\n",
      "Epoch 64/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13467891.0000 - val_loss: 8701989.0000\n",
      "Epoch 65/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13394020.0000 - val_loss: 7972978.5000\n",
      "Epoch 66/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13168566.0000 - val_loss: 6894945.0000\n",
      "Epoch 67/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13245276.0000 - val_loss: 7686947.5000\n",
      "Epoch 68/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13259435.0000 - val_loss: 7209145.0000\n",
      "Epoch 69/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13385166.0000 - val_loss: 6412449.5000\n",
      "Epoch 70/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13155812.0000 - val_loss: 6291991.5000\n",
      "Epoch 71/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13078416.0000 - val_loss: 6855501.0000\n",
      "Epoch 72/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13029320.0000 - val_loss: 6681451.5000\n",
      "Epoch 73/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12885723.0000 - val_loss: 6729949.5000\n",
      "Epoch 74/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13069613.0000 - val_loss: 5936207.0000\n",
      "Epoch 75/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12928262.0000 - val_loss: 6665362.5000\n",
      "Epoch 76/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12964875.0000 - val_loss: 6579692.0000\n",
      "Epoch 77/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12911387.0000 - val_loss: 6283146.5000\n",
      "Epoch 78/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13002242.0000 - val_loss: 6408160.0000\n",
      "Epoch 79/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12926322.0000 - val_loss: 5760027.0000\n",
      "Epoch 80/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12827727.0000 - val_loss: 5708095.5000\n",
      "Epoch 81/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12859660.0000 - val_loss: 6523588.5000\n",
      "Epoch 82/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12779200.0000 - val_loss: 7216574.0000\n",
      "Epoch 83/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12755035.0000 - val_loss: 6739793.0000\n",
      "Epoch 84/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12911891.0000 - val_loss: 6050353.0000\n",
      "Epoch 85/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12789843.0000 - val_loss: 5569580.0000\n",
      "Epoch 86/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12767097.0000 - val_loss: 6453287.5000\n",
      "Epoch 87/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12742512.0000 - val_loss: 10053881.0000\n",
      "Epoch 88/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12765623.0000 - val_loss: 5765313.5000\n",
      "Epoch 89/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12607414.0000 - val_loss: 6421025.5000\n",
      "Epoch 90/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12680700.0000 - val_loss: 5163123.0000\n",
      "Epoch 91/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12781562.0000 - val_loss: 5998009.5000\n",
      "Epoch 92/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12598540.0000 - val_loss: 7019761.0000\n",
      "Epoch 93/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12565363.0000 - val_loss: 7193765.5000\n",
      "Epoch 94/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12717968.0000 - val_loss: 6222148.5000\n",
      "Epoch 95/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12738048.0000 - val_loss: 6915875.5000\n",
      "Epoch 96/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12609576.0000 - val_loss: 6655842.0000\n",
      "Epoch 97/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12553859.0000 - val_loss: 9575321.0000\n",
      "Epoch 98/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12675983.0000 - val_loss: 5629337.0000\n",
      "Epoch 99/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12634203.0000 - val_loss: 7860238.5000\n",
      "Epoch 100/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12415277.0000 - val_loss: 4848404.5000\n",
      "Epoch 101/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12604719.0000 - val_loss: 4924102.0000\n",
      "Epoch 102/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12554778.0000 - val_loss: 7125995.5000\n",
      "Epoch 103/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12483224.0000 - val_loss: 5481369.5000\n",
      "Epoch 104/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12558417.0000 - val_loss: 5301686.0000\n",
      "Epoch 105/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12521926.0000 - val_loss: 6355915.5000\n",
      "Epoch 106/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12389278.0000 - val_loss: 5135575.0000\n",
      "Epoch 107/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12658110.0000 - val_loss: 5864577.0000\n",
      "Epoch 108/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12513376.0000 - val_loss: 6175097.5000\n",
      "Epoch 109/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12400196.0000 - val_loss: 4547500.0000\n",
      "Epoch 110/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12565196.0000 - val_loss: 4490518.5000\n",
      "Epoch 111/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12352175.0000 - val_loss: 6079199.5000\n",
      "Epoch 112/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12486159.0000 - val_loss: 5816633.5000\n",
      "Epoch 113/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12225741.0000 - val_loss: 7664970.5000\n",
      "Epoch 114/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12476669.0000 - val_loss: 5872771.5000\n",
      "Epoch 115/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12387222.0000 - val_loss: 6200384.0000\n",
      "Epoch 116/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12379428.0000 - val_loss: 6270377.5000\n",
      "Epoch 117/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12341472.0000 - val_loss: 4507670.5000\n",
      "Epoch 118/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12309196.0000 - val_loss: 6313255.5000\n",
      "Epoch 119/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12337008.0000 - val_loss: 7372770.0000\n",
      "Epoch 120/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12364804.0000 - val_loss: 12795006.0000\n",
      "1219/1219 [==============================] - 1s 401us/step\n",
      "Epoch 1/200\n",
      "1422/1422 [==============================] - 3s 1ms/step - loss: 79000144.0000 - val_loss: 47926960.0000\n",
      "Epoch 2/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 40138416.0000 - val_loss: 38050724.0000\n",
      "Epoch 3/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 31135306.0000 - val_loss: 25675480.0000\n",
      "Epoch 4/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 22808224.0000 - val_loss: 19870616.0000\n",
      "Epoch 5/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 20760254.0000 - val_loss: 18514832.0000\n",
      "Epoch 6/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19984266.0000 - val_loss: 18577620.0000\n",
      "Epoch 7/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 19672958.0000 - val_loss: 17383482.0000\n",
      "Epoch 8/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19529030.0000 - val_loss: 16735169.0000\n",
      "Epoch 9/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 19299372.0000 - val_loss: 16586689.0000\n",
      "Epoch 10/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 18790624.0000 - val_loss: 16239401.0000\n",
      "Epoch 11/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18797988.0000 - val_loss: 15632653.0000\n",
      "Epoch 12/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18425502.0000 - val_loss: 16436047.0000\n",
      "Epoch 13/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18282488.0000 - val_loss: 14924337.0000\n",
      "Epoch 14/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 18239570.0000 - val_loss: 14823406.0000\n",
      "Epoch 15/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 17796820.0000 - val_loss: 14638467.0000\n",
      "Epoch 16/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 17484686.0000 - val_loss: 13760307.0000\n",
      "Epoch 17/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 17215250.0000 - val_loss: 13457081.0000\n",
      "Epoch 18/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16908944.0000 - val_loss: 12888422.0000\n",
      "Epoch 19/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16658309.0000 - val_loss: 13064281.0000\n",
      "Epoch 20/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16234605.0000 - val_loss: 12443870.0000\n",
      "Epoch 21/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 16059951.0000 - val_loss: 11458212.0000\n",
      "Epoch 22/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15927577.0000 - val_loss: 10830050.0000\n",
      "Epoch 23/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15785318.0000 - val_loss: 10848234.0000\n",
      "Epoch 24/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15562861.0000 - val_loss: 11159425.0000\n",
      "Epoch 25/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 15199875.0000 - val_loss: 10116750.0000\n",
      "Epoch 26/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 15197798.0000 - val_loss: 10015333.0000\n",
      "Epoch 27/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 15190261.0000 - val_loss: 9326585.0000\n",
      "Epoch 28/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14911884.0000 - val_loss: 9513810.0000\n",
      "Epoch 29/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14862588.0000 - val_loss: 8626529.0000\n",
      "Epoch 30/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14816965.0000 - val_loss: 8533581.0000\n",
      "Epoch 31/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14859801.0000 - val_loss: 8674032.0000\n",
      "Epoch 32/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14655558.0000 - val_loss: 8282958.0000\n",
      "Epoch 33/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14817495.0000 - val_loss: 9712295.0000\n",
      "Epoch 34/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14508919.0000 - val_loss: 9109533.0000\n",
      "Epoch 35/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14384083.0000 - val_loss: 8969815.0000\n",
      "Epoch 36/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14447053.0000 - val_loss: 8145820.0000\n",
      "Epoch 37/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14475805.0000 - val_loss: 8126626.0000\n",
      "Epoch 38/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14298025.0000 - val_loss: 9886158.0000\n",
      "Epoch 39/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14456012.0000 - val_loss: 8890689.0000\n",
      "Epoch 40/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14252401.0000 - val_loss: 8673929.0000\n",
      "Epoch 41/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14373559.0000 - val_loss: 7872103.5000\n",
      "Epoch 42/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14002775.0000 - val_loss: 7760609.5000\n",
      "Epoch 43/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 14042194.0000 - val_loss: 9048939.0000\n",
      "Epoch 44/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 13920404.0000 - val_loss: 7482483.0000\n",
      "Epoch 45/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 13765726.0000 - val_loss: 7670731.5000\n",
      "Epoch 46/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 13975958.0000 - val_loss: 7432027.5000\n",
      "Epoch 47/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 13838768.0000 - val_loss: 7008728.5000\n",
      "Epoch 48/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13856255.0000 - val_loss: 7267464.5000\n",
      "Epoch 49/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13721112.0000 - val_loss: 7120574.0000\n",
      "Epoch 50/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13729848.0000 - val_loss: 7444212.5000\n",
      "Epoch 51/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13764365.0000 - val_loss: 7327922.0000\n",
      "Epoch 52/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13580586.0000 - val_loss: 6842754.5000\n",
      "Epoch 53/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13527423.0000 - val_loss: 7189554.5000\n",
      "Epoch 54/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13532229.0000 - val_loss: 6467995.5000\n",
      "Epoch 55/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13402626.0000 - val_loss: 6743835.0000\n",
      "Epoch 56/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13330551.0000 - val_loss: 6388949.5000\n",
      "Epoch 57/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13307966.0000 - val_loss: 6490813.0000\n",
      "Epoch 58/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13285939.0000 - val_loss: 6477323.0000\n",
      "Epoch 59/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13374050.0000 - val_loss: 6447883.5000\n",
      "Epoch 60/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13160533.0000 - val_loss: 6124522.0000\n",
      "Epoch 61/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13329923.0000 - val_loss: 9888120.0000\n",
      "Epoch 62/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13176363.0000 - val_loss: 5918524.0000\n",
      "Epoch 63/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13108599.0000 - val_loss: 6187541.0000\n",
      "Epoch 64/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13246472.0000 - val_loss: 5951658.0000\n",
      "Epoch 65/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13197869.0000 - val_loss: 6172207.0000\n",
      "Epoch 66/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12933080.0000 - val_loss: 5781284.5000\n",
      "Epoch 67/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12808562.0000 - val_loss: 5492840.0000\n",
      "Epoch 68/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13103448.0000 - val_loss: 5514384.0000\n",
      "Epoch 69/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13061339.0000 - val_loss: 6623803.0000\n",
      "Epoch 70/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12961857.0000 - val_loss: 5672312.0000\n",
      "Epoch 71/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12978954.0000 - val_loss: 5750607.5000\n",
      "Epoch 72/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12902543.0000 - val_loss: 5914473.5000\n",
      "Epoch 73/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 13058178.0000 - val_loss: 5222682.5000\n",
      "Epoch 74/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12905073.0000 - val_loss: 6295773.5000\n",
      "Epoch 75/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12963551.0000 - val_loss: 5263252.5000\n",
      "Epoch 76/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12953792.0000 - val_loss: 4827217.5000\n",
      "Epoch 77/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12738042.0000 - val_loss: 5190280.0000\n",
      "Epoch 78/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12826046.0000 - val_loss: 5555481.5000\n",
      "Epoch 79/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12923840.0000 - val_loss: 5684747.0000\n",
      "Epoch 80/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12918926.0000 - val_loss: 4920719.5000\n",
      "Epoch 81/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12907521.0000 - val_loss: 5301968.0000\n",
      "Epoch 82/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12689145.0000 - val_loss: 5184423.0000\n",
      "Epoch 83/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12781692.0000 - val_loss: 6548568.5000\n",
      "Epoch 84/200\n",
      "1422/1422 [==============================] - 2s 2ms/step - loss: 12762960.0000 - val_loss: 5744808.0000\n",
      "Epoch 85/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12611442.0000 - val_loss: 4634171.5000\n",
      "Epoch 86/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12560061.0000 - val_loss: 5203847.0000\n",
      "Epoch 87/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12724471.0000 - val_loss: 8004827.5000\n",
      "Epoch 88/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12877884.0000 - val_loss: 5683906.5000\n",
      "Epoch 89/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12661101.0000 - val_loss: 9816932.0000\n",
      "Epoch 90/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12788645.0000 - val_loss: 4976245.0000\n",
      "Epoch 91/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12675491.0000 - val_loss: 4668620.5000\n",
      "Epoch 92/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12654847.0000 - val_loss: 5576279.5000\n",
      "Epoch 93/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12477604.0000 - val_loss: 6578243.5000\n",
      "Epoch 94/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12597719.0000 - val_loss: 6716179.5000\n",
      "Epoch 95/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12646740.0000 - val_loss: 4410426.0000\n",
      "Epoch 96/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12541063.0000 - val_loss: 7586913.0000\n",
      "Epoch 97/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12546573.0000 - val_loss: 5192548.0000\n",
      "Epoch 98/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12524562.0000 - val_loss: 5266282.0000\n",
      "Epoch 99/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12634742.0000 - val_loss: 4226481.5000\n",
      "Epoch 100/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12522269.0000 - val_loss: 4425482.0000\n",
      "Epoch 101/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12546193.0000 - val_loss: 3712923.5000\n",
      "Epoch 102/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12440620.0000 - val_loss: 4682232.5000\n",
      "Epoch 103/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12597215.0000 - val_loss: 5399594.0000\n",
      "Epoch 104/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12503570.0000 - val_loss: 5096955.5000\n",
      "Epoch 105/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12490133.0000 - val_loss: 4247593.0000\n",
      "Epoch 106/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12404993.0000 - val_loss: 5087367.0000\n",
      "Epoch 107/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12571784.0000 - val_loss: 4175688.7500\n",
      "Epoch 108/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12504365.0000 - val_loss: 6684130.0000\n",
      "Epoch 109/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12498820.0000 - val_loss: 5845683.5000\n",
      "Epoch 110/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12386065.0000 - val_loss: 4405280.5000\n",
      "Epoch 111/200\n",
      "1422/1422 [==============================] - 2s 1ms/step - loss: 12666926.0000 - val_loss: 6300235.5000\n",
      "4063/4063 [==============================] - 2s 400us/step\n",
      "‚úÖ NN1_v9 complete ‚Äî top model trained, saved, and evaluated.\n"
     ]
    }
   ],
   "source": [
    "# === 0. Imports and Seed Setup ===\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# === 1. Load and Preprocess Data ===\n",
    "df = pd.read_csv(\"combined_feedstocks_dataset.csv\")\n",
    "\n",
    "df.drop(columns=[\n",
    "    'syn_H2', 'syn_CO', 'syn_CO2', 'syn_CH4', 'syn_C2Hn', 'syn_N2',\n",
    "    'syn_LHV', 'syn_tar_content', 'syn_yield', 'syn_char_yield'\n",
    "], errors='ignore', inplace=True)\n",
    "\n",
    "groups = df[\"Iteration\"]\n",
    "df.drop(columns=[\"Feedstock_ID\", \"Year\"], inplace=True)\n",
    "\n",
    "X = df.drop(columns=[\"ANNUALENERGY_H2_kwh\", \"Iteration\"]).values\n",
    "y = df[[\"ANNUALENERGY_H2_kwh\"]].values\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    if np.isnan(X[:, i]).any():\n",
    "        X[:, i][np.isnan(X[:, i])] = np.nanmedian(X[:, i])\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(X, y, groups))\n",
    "X_train, X_val = X[train_idx], X[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# === 2. Define Heavy Grid Combos (v9) ===\n",
    "combos = [\n",
    "    ([238, 238, 238], 'relu', 0.05, 0.0005),\n",
    "    ([256, 128, 64], 'relu', 0.05, 0.0005),\n",
    "    ([128, 128, 64, 32], 'relu', 0.05, 0.0005),\n",
    "    ([238, 128, 64, 32], 'relu', 0.1, 0.0005),\n",
    "    ([238, 238, 128, 64, 32], 'relu', 0.05, 0.0001)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "def build_model(neurons, activation, dropout, l2_strength):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], activation=activation, input_shape=(X_train.shape[1],),\n",
    "                    kernel_regularizer=regularizers.l2(l2_strength)))\n",
    "    model.add(Dropout(dropout))\n",
    "    for n in neurons[1:]:\n",
    "        model.add(Dense(n, activation=activation, kernel_regularizer=regularizers.l2(l2_strength)))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "# === 3. Grid Search ===\n",
    "for idx, (neurons, activation, dropout, l2_strength) in enumerate(combos):\n",
    "    print(f\"\\nüîÅ Running combo {idx+1}/{len(combos)}: {neurons}, {activation}, dropout={dropout}, l2={l2_strength}\")\n",
    "    model = build_model(neurons, activation, dropout, l2_strength)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train, epochs=200, batch_size=64, verbose=1,\n",
    "        validation_data=(X_val, y_val), callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_val).flatten()\n",
    "    y_true = y_val.flatten()\n",
    "\n",
    "    results.append({\n",
    "        'neurons': str(neurons),\n",
    "        'activation': activation,\n",
    "        'dropout': dropout,\n",
    "        'l2_strength': l2_strength,\n",
    "        'val_loss': min(history.history['val_loss']),\n",
    "        'r2': r2_score(y_true, y_pred),\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'epochs_ran': len(history.history['val_loss'])\n",
    "    })\n",
    "\n",
    "# === 4. Save Grid Results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by='val_loss', inplace=True)\n",
    "results_df.to_csv(\"grid_search_results_NN1_v9.csv\", index=False)\n",
    "\n",
    "# === 5. Train Best Model ===\n",
    "top = results_df.iloc[0]\n",
    "neurons = eval(top['neurons'])\n",
    "activation = top['activation']\n",
    "dropout = top['dropout']\n",
    "l2_strength = top['l2_strength']\n",
    "\n",
    "model = build_model(neurons, activation, dropout, l2_strength)\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=200, batch_size=64, verbose=1,\n",
    "    validation_data=(X_val, y_val), callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# === 6. Evaluate ===\n",
    "y_pred = model.predict(X).flatten()\n",
    "y_true = y.flatten()\n",
    "\n",
    "percentage_diff = ((y_pred - y_true) / y_true) * 100\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "msd = np.mean(y_true - y_pred)\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "# === 7. Save Outputs ===\n",
    "model.save(\"best_model_allfeedstocks_NN1_v9.keras\")\n",
    "pd.DataFrame({\n",
    "    'Row ID': range(1, len(y_true)+1),\n",
    "    'Actual H2 (kWh/year)': y_true,\n",
    "    'Predicted H2 (kWh/year)': y_pred,\n",
    "    'Percentage Difference (%)': percentage_diff\n",
    "}).to_csv(\"predicted_vs_actual_ANNUALENERGY_H2_kwh_NN1_v9.csv\", index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Characteristic': ['Model Version', 'Number of Layers', 'Neurons per Layer', 'Activation Functions',\n",
    "                       'Epochs', 'Train/Test Split', 'Optimizer', 'Regularisation Strength', 'Dropout Rate'],\n",
    "    'Value': ['NN1_v9', len(model.layers), neurons,\n",
    "              [layer.activation.__name__ for layer in model.layers if hasattr(layer, 'activation')],\n",
    "              len(history.history['loss']), f\"{X_train.shape[0]}:{X_val.shape[0]}\",\n",
    "              'adam', l2_strength, dropout]\n",
    "}).to_csv(\"model_characteristics_NN1_v9.csv\", index=False)\n",
    "\n",
    "# === 8. Plots ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.5, edgecolors='k')\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "plt.xlabel(\"Actual H2 (kWh/year)\")\n",
    "plt.ylabel(\"Predicted H2 (kWh/year)\")\n",
    "plt.title(\"All Feedstocks - Actual vs Predicted Hydrogen Yield (NN1_v9)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"h2_prediction_plot_NN1_v9.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE (kWh)\")\n",
    "plt.title(\"Training vs Validation Loss (NN1_v9)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_curve_NN1_v9.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"‚úÖ NN1_v9 complete ‚Äî top model trained, saved, and evaluated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23627d92-6233-45c6-8434-4e08b093cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= FINAL MODEL PERFORMANCE METRICS (NN1_v9) =========================\n",
      "Best Neural Configuration: [238, 238, 128, 64, 32], activation=relu, dropout=0.05, L2=0.0001\n",
      "R¬≤: 0.9994\n",
      "MAE (kWh): 3,588,551.81\n",
      "RMSE (kWh): 9,304,747.19\n",
      "Mean Signed Deviation (MSD) (kWh): -282,537.58\n",
      "Mean Absolute Percentage Error (MAPE): 5.61%\n",
      "Validation Loss (MAE, kWh): 3,712,926.5\n",
      "Epochs Trained: 111\n",
      "\n",
      "Network Architecture:\n",
      "  Layer 1: Dense        | Units: 238  | Activation: relu\n",
      "  Layer 2: Dropout      | Units: -    | Activation: -\n",
      "  Layer 3: Dense        | Units: 238  | Activation: relu\n",
      "  Layer 4: Dropout      | Units: -    | Activation: -\n",
      "  Layer 5: Dense        | Units: 128  | Activation: relu\n",
      "  Layer 6: Dropout      | Units: -    | Activation: -\n",
      "  Layer 7: Dense        | Units: 64   | Activation: relu\n",
      "  Layer 8: Dropout      | Units: -    | Activation: -\n",
      "  Layer 9: Dense        | Units: 32   | Activation: relu\n",
      "  Layer 10: Dropout      | Units: -    | Activation: -\n",
      "  Layer 11: Dense        | Units: 1    | Activation: linear\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# === 9. Print Final Model Performance Summary ===\n",
    "print(\"\\n\" + \"=\"*25 + \" FINAL MODEL PERFORMANCE METRICS (NN1_v9) \" + \"=\"*25)\n",
    "\n",
    "print(f\"Best Neural Configuration: {neurons}, activation={activation}, dropout={dropout}, L2={l2_strength}\")\n",
    "print(f\"R¬≤: {round(r2, 4)}\")\n",
    "print(f\"MAE (kWh): {round(mae, 2):,}\")\n",
    "print(f\"RMSE (kWh): {round(rmse, 2):,}\")\n",
    "print(f\"Mean Signed Deviation (MSD) (kWh): {round(msd, 2):,}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {round(mape, 2)}%\")\n",
    "print(f\"Validation Loss (MAE, kWh): {round(val_loss, 2):,}\")\n",
    "print(f\"Epochs Trained: {len(history.history['loss'])}\")\n",
    "\n",
    "print(\"\\nNetwork Architecture:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    config = layer.get_config()\n",
    "    layer_type = type(layer).__name__\n",
    "    units = config.get('units', '-')\n",
    "    act = config.get('activation', '-')\n",
    "    print(f\"  Layer {i+1}: {layer_type:<12} | Units: {units:<4} | Activation: {act}\")\n",
    "\n",
    "print(\"=\"*85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd5025d-4d98-419a-ba6c-c1257f1bcbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ANNUALENERGY_H2_kwh', 'Population', 'Waste_per_capita', 'WasteTotal', 'recovery_H2_separation', 'recovery_H2_storage', 'eff_CGE', 'eff_CCE', 'ratio_H2_stored', 'ratio_H2_CHP', 'is_plasma_cleanup', 'fs_shape_pellets', 'fs_shape_fibres', 'fs_shape_dust', 'fs_shape_chips', 'fs_shape_particles', 'fs_shape_other', 'fs_size', 'fs_lhv', 'fs_C', 'fs_H', 'fs_N', 'fs_S', 'fs_O', 'fs_ash', 'fs_moisture', 're_temp', 're_mode_continuous', 're_mode_batch', 're_ER', 're_steambiomass_ratio', 're_agent_air', 're_agent_air_and_steam', 're_agent_oxygen', 're_agent_steam', 're_agent_other', 're_type_fluidised_bed', 're_type_fixed_bed', 're_type_other', 're_material_olivine', 're_material_silica', 're_material_dolomite', 're_material_alumina', 're_material_calcium_oxide', 're_catalyst', 're_scale_pilot', 're_scale_lab', 'syn_N2', 'syn_H2', 'syn_CO', 'syn_CO2', 'syn_CH4', 'syn_C2Hn', 'syn_LHV', 'syn_tar_content', 'syn_yield', 'syn_char_yield', 'Feedstock_ID', 'Iteration', 'Year', 'feedstock_type_HB', 'feedstock_type_MSW', 'feedstock_type_Other', 'feedstock_type_Plastics', 'feedstock_type_WB']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('combined_feedstocks_dataset.csv')\n",
    "\n",
    "# Print all column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36614923-ad14-482e-96da-7f39722abf88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
