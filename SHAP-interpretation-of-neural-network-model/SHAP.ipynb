{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a5963-b844-47b7-821d-ade925ba1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIG ANALYSIS OF ALL FEEDSTOCKS SEPARATELY, MAY TAKE A WHILE TO RUN FULL-SCALE VERSION #####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Mapping features to full English\n",
    "varname_map = {\n",
    "    'Population': 'Population',\n",
    "    'Waste_per_capita': 'Waste per Capita',\n",
    "    'WasteTotal': 'Total Waste',\n",
    "    'recovery_H2_separation': 'H₂ Recovery (Separation)',\n",
    "    'recovery_H2_storage': 'H₂ Recovery (Storage)',\n",
    "    'eff_CGE': 'Cold Gas Efficiency',\n",
    "    'eff_CCE': 'Carbon Conversion Efficiency',\n",
    "    'ratio_H2_stored': 'H₂ Allocation to Storage',\n",
    "    'ratio_H2_CHP': 'H₂ Allocation to CHP',\n",
    "    'is_plasma_cleanup': 'Plasma Gas Cleaning',\n",
    "    'fs_shape_pellets': 'Pellet Shape',\n",
    "    'fs_shape_fibres': 'Fibre Shape',\n",
    "    'fs_shape_dust': 'Dust Shape',\n",
    "    'fs_shape_chips': 'Chip Shape',\n",
    "    'fs_shape_particles': 'Particle Shape',\n",
    "    'fs_shape_other': 'Other Shape',\n",
    "    'fs_size': 'Feedstock Size',\n",
    "    'fs_lhv': 'Feedstock LHV',\n",
    "    'fs_C': 'Carbon Content',\n",
    "    'fs_H': 'Hydrogen Content',\n",
    "    'fs_N': 'Nitrogen Content',\n",
    "    'fs_S': 'Sulphur Content',\n",
    "    'fs_O': 'Oxygen Content',\n",
    "    'fs_ash': 'Ash Content',\n",
    "    'fs_moisture': 'Moisture Content',\n",
    "    're_temp': 'Reactor Temperature',\n",
    "    're_mode_continuous': 'Continuous Reactor',\n",
    "    're_mode_batch': 'Batch Reactor',\n",
    "    're_ER': 'Equivalence Ratio',\n",
    "    're_steambiomass_ratio': 'Steam-to-Biomass Ratio',\n",
    "    're_agent_air': 'Gasifying Agent: Air',\n",
    "    're_agent_air_and_steam': 'Gasifying Agent: Air + Steam',\n",
    "    're_agent_oxygen': 'Gasifying Agent: Oxygen',\n",
    "    're_agent_steam': 'Gasifying Agent: Steam',\n",
    "    're_agent_other': 'Gasifying Agent: Other',\n",
    "    're_type_fluidised_bed': 'Fluidised Bed Reactor',\n",
    "    're_type_fixed_bed': 'Fixed Bed Reactor',\n",
    "    're_type_other': 'Other Reactor Type',\n",
    "    're_material_olivine': 'Reactor Material: Olivine',\n",
    "    're_material_silica': 'Reactor Material: Silica',\n",
    "    're_material_dolomite': 'Reactor Material: Dolomite',\n",
    "    're_material_alumina': 'Reactor Material: Alumina',\n",
    "    're_material_calcium_oxide': 'Reactor Material: CaO',\n",
    "    're_catalyst': 'Catalyst Present',\n",
    "    're_scale_pilot': 'Pilot Scale',\n",
    "    're_scale_lab': 'Lab Scale',\n",
    "    'syn_N2': 'Syngas N₂',\n",
    "    'syn_H2': 'Syngas H₂',\n",
    "    'syn_CO': 'Syngas CO',\n",
    "    'syn_CO2': 'Syngas CO₂',\n",
    "    'syn_CH4': 'Syngas CH₄',\n",
    "    'syn_C2Hn': 'Syngas C₂Hn',\n",
    "    'syn_LHV': 'Syngas LHV',\n",
    "    'syn_tar_content': 'Tar Content',\n",
    "    'syn_yield': 'Syngas Yield',\n",
    "    'syn_char_yield': 'Char Yield',\n",
    "    'Feedstock_ID': 'Feedstock ID',\n",
    "    'Iteration': 'Iteration',\n",
    "    'Year': 'Year',\n",
    "    'feedstock_type_HB': 'Herbaceous Biomass',\n",
    "    'feedstock_type_MSW': 'Municipal Solid Waste',\n",
    "    'feedstock_type_Other': 'Other Feedstock',\n",
    "    'feedstock_type_Plastics': 'Plastics',\n",
    "    'feedstock_type_WB': 'Woody Biomass'\n",
    "}\n",
    "\n",
    "# Load and preprocess input data\n",
    "df = pd.read_csv(\"monte_carlo_results.csv\")\n",
    "\n",
    "columns_to_drop = [\n",
    "    'syn_H2', 'syn_CO', 'syn_CO2', 'syn_CH4', 'syn_C2Hn', 'syn_N2',\n",
    "    'syn_LHV', 'syn_tar_content', 'syn_yield', 'syn_char_yield'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "feedstock_cols = [col for col in df.columns if col.startswith(\"feedstock_type_\")]\n",
    "feedstock_labels = [col.replace(\"feedstock_type_\", \"\") for col in feedstock_cols]\n",
    "\n",
    "df.drop(columns=[\"Feedstock_ID\", \"Year\"], inplace=True)\n",
    "groups = df[\"Iteration\"]\n",
    "X_df = df.drop(columns=[\"ANNUALENERGY_H2_kwh\", \"Iteration\"])\n",
    "y = df[\"ANNUALENERGY_H2_kwh\"].values\n",
    "\n",
    "for col in X_df.columns:\n",
    "    if X_df[col].isnull().any():\n",
    "        X_df[col] = X_df[col].fillna(X_df[col].median())\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_df)\n",
    "feature_names = X_df.columns.tolist()\n",
    "feature_labels = [varname_map.get(f, f) for f in feature_names]\n",
    "\n",
    "# Load neural network model\n",
    "model = load_model(\"best_model_allfeedstocks_NN1_v9.keras\")\n",
    "\n",
    "# Sample 500 representative rows across entire dataset\n",
    "sample_count = 500\n",
    "sample_indices = np.linspace(0, X_scaled.shape[0] - 1, sample_count, dtype=int)\n",
    "X_sampled = X_scaled[sample_indices]\n",
    "\n",
    "# SHAP on full dataset\n",
    "explainer = shap.KernelExplainer(model.predict, X_sampled)\n",
    "shap_values_list = explainer.shap_values(X_sampled)\n",
    "shap_values_array = shap_values_list[0] if isinstance(shap_values_list, list) else shap_values_list\n",
    "\n",
    "# Compute global importance ranking\n",
    "importances = np.abs(shap_values_array).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Feature_Label\": feature_labels,\n",
    "    \"Mean_Abs_SHAP\": importances\n",
    "}).sort_values(by=\"Mean_Abs_SHAP\", ascending=False)\n",
    "\n",
    "# Saving results\n",
    "pd.DataFrame(shap_values_array, columns=feature_labels).to_csv(\"shap_values.csv\", index=False)\n",
    "pd.DataFrame(X_sampled, columns=feature_labels).to_csv(\"shap_inputs.csv\", index=False)\n",
    "importance_df.to_csv(\"shap_importance_ranking.csv\", index=False)\n",
    "\n",
    "# Plotting\n",
    "def plot_summary(shap_vals, X_data, fname, max_display, plot_type='dot'):\n",
    "    shap.summary_plot(\n",
    "        shap_vals, features=X_data, feature_names=feature_labels,\n",
    "        plot_type=plot_type, max_display=max_display, show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Global plots\n",
    "plot_summary(shap_values_array, X_sampled, \"SHAP_dot_top10.png\", max_display=10, plot_type='dot')\n",
    "plot_summary(shap_values_array, X_sampled, \"SHAP_bar_top10.png\", max_display=10, plot_type='bar')\n",
    "plot_summary(shap_values_array, X_sampled, \"SHAP_dot_top20.png\", max_display=20, plot_type='dot')\n",
    "plot_summary(shap_values_array, X_sampled, \"SHAP_bar_top20.png\", max_display=20, plot_type='bar')\n",
    "plot_summary(shap_values_array, X_sampled, \"SHAP_dot_all.png\", max_display=len(feature_labels), plot_type='dot')\n",
    "plot_summary(shap_values_array, X_sampled, \"SHAP_bar_all.png\", max_display=len(feature_labels), plot_type='bar')\n",
    "\n",
    "# Per-feedstock plots\n",
    "for col, label in zip(feedstock_cols, feedstock_labels):\n",
    "    feedstock_df = df[df[col] == 1].copy()\n",
    "    X_f = feedstock_df.drop(columns=[\"ANNUALENERGY_H2_kwh\", \"Iteration\"])\n",
    "    y_f = feedstock_df[\"ANNUALENERGY_H2_kwh\"]\n",
    "\n",
    "    for feat in X_f.columns:\n",
    "        if X_f[feat].isnull().any():\n",
    "            X_f[feat] = X_f[feat].fillna(X_f[feat].median())\n",
    "\n",
    "    X_scaled_f = scaler_X.transform(X_f)\n",
    "    sample_count_f = min(500, X_scaled_f.shape[0])  # cap to 500 or fewer if small dataset\n",
    "    sample_idx = np.linspace(0, X_scaled_f.shape[0] - 1, sample_count_f, dtype=int)\n",
    "    X_sampled_f = X_scaled_f[sample_idx]\n",
    "\n",
    "\n",
    "    explainer_f = shap.KernelExplainer(model.predict, X_sampled_f)\n",
    "    shap_vals_f = explainer_f.shap_values(X_sampled_f)\n",
    "    shap_arr_f = shap_vals_f[0] if isinstance(shap_vals_f, list) else shap_vals_f\n",
    "\n",
    "    plot_summary(shap_arr_f, X_sampled_f, f\"SHAP_dot_top5_{label}.png\", max_display=5, plot_type='dot')\n",
    "    plot_summary(shap_arr_f, X_sampled_f, f\"SHAP_bar_top5_{label}.png\", max_display=5, plot_type='bar')\n",
    "    plot_summary(shap_arr_f, X_sampled_f, f\"SHAP_dot_top10_{label}.png\", max_display=10, plot_type='dot')\n",
    "    plot_summary(shap_arr_f, X_sampled_f, f\"SHAP_bar_top10_{label}.png\", max_display=10, plot_type='bar')\n",
    "    plot_summary(shap_arr_f, X_sampled_f, f\"SHAP_dot_all_{label}.png\", max_display=len(feature_labels), plot_type='dot')\n",
    "    plot_summary(shap_arr_f, X_sampled_f, f\"SHAP_bar_all_{label}.png\", max_display=len(feature_labels), plot_type='bar')\n",
    "\n",
    "# Confirmation statements\n",
    "print(\" SHAP 5-sample test complete.\")\n",
    "print(\"• Global plots: 6 files\")\n",
    "print(\"• Per-feedstock plots: 6 × 5 feedstocks = 30 files\")\n",
    "print(\"• CSVs saved with readable labels.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
